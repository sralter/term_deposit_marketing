{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5227e004-7c3d-4d64-824d-36df80facdbf",
   "metadata": {
    "id": "5227e004-7c3d-4d64-824d-36df80facdbf"
   },
   "source": [
    "# Term Deposit Marketing - An Apziva Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13caaf73-d640-4bae-8ee1-f8b07ff73ed1",
   "metadata": {
    "id": "13caaf73-d640-4bae-8ee1-f8b07ff73ed1"
   },
   "source": [
    "By Samuel Alter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1066f-6628-43fc-abdb-fee10e55e68a",
   "metadata": {
    "id": "dcc1066f-6628-43fc-abdb-fee10e55e68a"
   },
   "source": [
    "Apziva: G3SuQYZYrFt9dwF3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9623536a-e44e-4fda-8dc5-0e5ed6282c62",
   "metadata": {
    "id": "9623536a-e44e-4fda-8dc5-0e5ed6282c62"
   },
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b04356-770c-4b85-8823-5d6f7dec2f19",
   "metadata": {
    "id": "95b04356-770c-4b85-8823-5d6f7dec2f19"
   },
   "source": [
    "Using phone call data from a European bank, this project will be building a model that predicts if a customer will subscribe to a term deposit, a type of financial product. This project is a partnership with a startup focused on providing ML solutions for European banks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523ee87-ca0b-4efc-80b1-86d7c3f5770f",
   "metadata": {
    "id": "0523ee87-ca0b-4efc-80b1-86d7c3f5770f",
    "tags": []
   },
   "source": [
    "### Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22534a75-16be-4d77-9a59-8f92436c1700",
   "metadata": {
    "id": "22534a75-16be-4d77-9a59-8f92436c1700"
   },
   "source": [
    "The startup is hoping that I can **achieve ≥81% accuracy** using a 5-fold cross validation strategy, taking the average performance score.\n",
    "\n",
    "Bonus goals include:\n",
    "* Determining which customers are most likely to buy the term deposit loan\n",
    "  * Which segments of customers should the client prioritize?\n",
    "* Determine what makes the customer buy the loan\n",
    "  * Which feature should the startup focus on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e9346-3220-4860-b609-22540ad7fb6e",
   "metadata": {
    "id": "c73e9346-3220-4860-b609-22540ad7fb6e"
   },
   "source": [
    "### The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561d828-da7d-49a6-a990-be0ab899e90f",
   "metadata": {
    "id": "f561d828-da7d-49a6-a990-be0ab899e90f"
   },
   "source": [
    "Using phone call data from a European bank, this project will be building models that predict if a customer will subscribe to a term deposit, a type of financial product. This project is a partnership with a startup focused on providing ML solutions for European banks.\n",
    "\n",
    "The dataset consists of the following columns:\n",
    "* `age`\n",
    "  * Numeric\n",
    "  * The age of the customer\n",
    "* `job`\n",
    "  * Categorical\n",
    "  * The job category of the customer\n",
    "* `marital`\n",
    "  * Categorical\n",
    "  * Whether the customer is married\n",
    "* `education`\n",
    "  * Categorical\n",
    "  * The customer's level of education\n",
    "* `default`\n",
    "  * Binary\n",
    "  * If the customer has credit in default or not\n",
    "* `balance`\n",
    "  * Numeric\n",
    "  * Average yearly balance in Euros\n",
    "* `housing`\n",
    "  * Binary\n",
    "  * If the customer has a housing loan or not\n",
    "* `loan`\n",
    "  * Binary\n",
    "  * If the customer has a personal loan\n",
    "* `contact`\n",
    "  * Categorical\n",
    "  * The type of contact communication\n",
    "* `day`\n",
    "  * Numeric\n",
    "  * Last contact day of the month\n",
    "* `month`\n",
    "  * Categorical\n",
    "  * Last contact month of the year\n",
    "* `duration`\n",
    "  * Numeric\n",
    "  * Duration of the last phone call with the customer\n",
    "* `campaign`\n",
    "  * Numeric\n",
    "  * The number of contacts performed during this campaign and for this client, which includes the last contact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a70ee-45dd-402c-b132-593a220dabec",
   "metadata": {
    "id": "866a70ee-45dd-402c-b132-593a220dabec"
   },
   "source": [
    "The final column, `y`, is the target of the dataset and shows whether the client subscribed to a term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15887c-7c0d-4e8a-a6ac-8b1245917fe1",
   "metadata": {
    "id": "4f15887c-7c0d-4e8a-a6ac-8b1245917fe1"
   },
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d80d5-bba0-4c15-872b-a71026f545a4",
   "metadata": {
    "id": "d98d80d5-bba0-4c15-872b-a71026f545a4"
   },
   "source": [
    "1. [EDA](#eda)\n",
    " * [Non-visual data analysis](#neda) of the data: check `dtype`, look at broad trends in data\n",
    " * [Visualization](#viz) of the data\n",
    "   * [Figure 1: Barplots of **categorical** features](#fig1)\n",
    "   * [Figure 2: Histograms of **continuous** features](#fig2)\n",
    "   * [Figure 3: Boxplots of **continuous** features](#fig3)\n",
    "   * [Figure 4: Correlation matrix of **continuous** features](#fig4)\n",
    "   * [Figure 5: Correlation matrix of **categorical** features](#fig5)\n",
    "   * What about [scatterplots?](#scat)\n",
    "2. [Modeling](#mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec43663-7e38-44ee-80d5-df9885aa7c12",
   "metadata": {
    "id": "cec43663-7e38-44ee-80d5-df9885aa7c12"
   },
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a73c419-37ae-4e69-9b29-fbaf125cbf09",
   "metadata": {
    "id": "7a73c419-37ae-4e69-9b29-fbaf125cbf09"
   },
   "outputs": [],
   "source": [
    "# ignore warnings for seaborn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78cdd4e-1834-4000-8729-d027851edd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: python: not found\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13439630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package              Version\n",
      "-------------------- -----------\n",
      "argon2-cffi          21.3.0\n",
      "argon2-cffi-bindings 21.2.0\n",
      "asttokens            2.0.8\n",
      "attrs                22.1.0\n",
      "auto-sklearn         0.15.0\n",
      "backcall             0.2.0\n",
      "beautifulsoup4       4.11.1\n",
      "black                22.8.0\n",
      "bleach               5.0.1\n",
      "certifi              2022.9.14\n",
      "cffi                 1.15.1\n",
      "cfgv                 3.3.1\n",
      "charset-normalizer   2.1.1\n",
      "click                8.1.3\n",
      "cloudpickle          2.2.0\n",
      "ConfigSpace          0.4.21\n",
      "contourpy            1.0.5\n",
      "coverage             6.4.4\n",
      "cycler               0.11.0\n",
      "Cython               0.29.32\n",
      "dask                 2022.9.1\n",
      "debugpy              1.6.3\n",
      "decopatch            1.4.10\n",
      "decorator            5.1.1\n",
      "defusedxml           0.7.1\n",
      "distlib              0.3.6\n",
      "distributed          2022.9.1\n",
      "distro               1.7.0\n",
      "emcee                3.1.2\n",
      "entrypoints          0.4\n",
      "execnet              1.9.0\n",
      "executing            1.0.0\n",
      "fastjsonschema       2.16.2\n",
      "filelock             3.8.0\n",
      "fonttools            4.37.2\n",
      "fsspec               2022.8.2\n",
      "HeapDict             1.0.1\n",
      "identify             2.5.5\n",
      "idna                 3.4\n",
      "importlib-metadata   4.12.0\n",
      "importlib-resources  5.9.0\n",
      "iniconfig            1.1.1\n",
      "ipykernel            6.15.3\n",
      "ipython              8.5.0\n",
      "ipython-genutils     0.2.0\n",
      "ipywidgets           8.0.2\n",
      "isort                5.10.1\n",
      "jedi                 0.18.1\n",
      "Jinja2               3.1.2\n",
      "joblib               1.2.0\n",
      "jsonschema           4.16.0\n",
      "jupyter              1.0.0\n",
      "jupyter-client       7.3.4\n",
      "jupyter-console      6.4.4\n",
      "jupyter-core         4.11.1\n",
      "jupyterlab-pygments  0.2.2\n",
      "jupyterlab-widgets   3.0.3\n",
      "kiwisolver           1.4.4\n",
      "liac-arff            2.5.0\n",
      "locket               1.0.0\n",
      "lxml                 4.9.1\n",
      "makefun              1.15.0\n",
      "MarkupSafe           2.1.1\n",
      "matplotlib           3.6.0\n",
      "matplotlib-inline    0.1.6\n",
      "minio                7.1.11\n",
      "mistune              2.0.4\n",
      "msgpack              1.0.4\n",
      "mypy                 0.971\n",
      "mypy-extensions      0.4.3\n",
      "nbclient             0.6.8\n",
      "nbconvert            7.0.0\n",
      "nbformat             5.5.0\n",
      "nest-asyncio         1.5.5\n",
      "nodeenv              1.7.0\n",
      "notebook             6.4.12\n",
      "numpy                1.23.3\n",
      "openml               0.12.2\n",
      "packaging            21.3\n",
      "pandas               1.5.0\n",
      "pandocfilters        1.5.0\n",
      "parso                0.8.3\n",
      "partd                1.3.0\n",
      "pathspec             0.10.1\n",
      "pexpect              4.8.0\n",
      "pickleshare          0.7.5\n",
      "Pillow               9.2.0\n",
      "pip                  22.2.2\n",
      "pkgutil_resolve_name 1.3.10\n",
      "platformdirs         2.5.2\n",
      "pluggy               1.0.0\n",
      "pre-commit           2.20.0\n",
      "prometheus-client    0.14.1\n",
      "prompt-toolkit       3.0.31\n",
      "psutil               5.9.2\n",
      "ptyprocess           0.7.0\n",
      "pure-eval            0.2.2\n",
      "py                   1.11.0\n",
      "pyarrow              9.0.0\n",
      "pycparser            2.21\n",
      "pydocstyle           6.1.1\n",
      "Pygments             2.13.0\n",
      "pynisher             0.6.4\n",
      "pyparsing            3.0.9\n",
      "pyrfr                0.8.3\n",
      "pyrsistent           0.18.1\n",
      "pytest               7.1.3\n",
      "pytest-cases         3.6.13\n",
      "pytest-cov           3.0.0\n",
      "pytest-forked        1.4.0\n",
      "pytest-timeout       2.1.0\n",
      "pytest-xdist         2.5.0\n",
      "python-dateutil      2.8.2\n",
      "pytz                 2022.2.1\n",
      "PyYAML               6.0\n",
      "pyzmq                24.0.0\n",
      "qtconsole            5.3.2\n",
      "QtPy                 2.2.0\n",
      "requests             2.28.1\n",
      "scikit-learn         0.24.2\n",
      "scipy                1.9.1\n",
      "seaborn              0.12.0\n",
      "Send2Trash           1.8.0\n",
      "setuptools           65.3.0\n",
      "six                  1.16.0\n",
      "smac                 1.2\n",
      "snowballstemmer      2.2.0\n",
      "sortedcontainers     2.4.0\n",
      "soupsieve            2.3.2.post1\n",
      "stack-data           0.5.0\n",
      "tblib                1.7.0\n",
      "terminado            0.15.0\n",
      "threadpoolctl        3.1.0\n",
      "tinycss2             1.1.1\n",
      "toml                 0.10.2\n",
      "tomli                2.0.1\n",
      "toolz                0.12.0\n",
      "tornado              6.1\n",
      "traitlets            5.4.0\n",
      "typing_extensions    4.3.0\n",
      "urllib3              1.26.12\n",
      "virtualenv           20.16.5\n",
      "wcwidth              0.2.5\n",
      "webencodings         0.5.1\n",
      "wheel                0.34.2\n",
      "widgetsnbextension   4.0.3\n",
      "xmltodict            0.13.0\n",
      "zict                 2.2.0\n",
      "zipp                 3.8.1\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.2'),)\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8039ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy is installed.\n",
      "pandas is installed.\n",
      "matplotlib is installed.\n",
      "seaborn is installed.\n",
      "scikit-learn is installed.\n",
      "auto-sklearn is installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.2'),)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run `pip list` and capture the output\n",
    "pip_list_output = subprocess.check_output(['pip', 'list']).decode('utf-8')\n",
    "\n",
    "# List of packages to check\n",
    "required_packages = ['numpy', 'pandas', 'matplotlib', 'seaborn', 'scikit-learn', 'auto-sklearn']\n",
    "\n",
    "# Check if the required packages are in the pip list output\n",
    "for package in required_packages:\n",
    "    if package in pip_list_output:\n",
    "        print(f\"{package} is installed.\")\n",
    "    else:\n",
    "        print(f\"{package} is NOT installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951fabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m63.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.23.3)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m101.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-2.0.32-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m132.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m103.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m172.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Collecting typing-extensions>=4\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (622 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m128.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: typing-extensions, tqdm, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 greenlet-3.0.3 optuna-3.6.1 sqlalchemy-2.0.32 tqdm-4.66.5 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.2'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2c9e0e-6abf-460b-81e3-4e2faa22b8ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "2b2c9e0e-6abf-460b-81e3-4e2faa22b8ac",
    "outputId": "c1c94d7b-40de-48ca-b99b-f9765fe4352e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from pycaret.classification import setup,compare_models,create_model,plot_model,evaluate_model\n",
    "# from pycaret.regression import *\n",
    "\n",
    "import optuna\n",
    "import autosklearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347e3a1-ee42-4530-8691-e81b491b69f1",
   "metadata": {
    "id": "3347e3a1-ee42-4530-8691-e81b491b69f1"
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# from datetime import datetime\n",
    "# from pathlib import Path\n",
    "# import inspect\n",
    "\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# from sklearn.metrics import roc_curve,auc,roc_auc_score\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from lightgbm import plot_importance\n",
    "\n",
    "# from sklearn.ensemble import StackingClassifier\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from numpy import mean\n",
    "# from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e5c419-09a9-4f1b-b79b-5b29f5283a4e",
   "metadata": {
    "id": "f9e5c419-09a9-4f1b-b79b-5b29f5283a4e"
   },
   "outputs": [],
   "source": [
    "# simple function to generate random integers\n",
    "\n",
    "def rand_gen(low=1,high=1e4):\n",
    "    '''\n",
    "    Generates a pseudo-random integer\n",
    "    consisting of up to four digits\n",
    "    '''\n",
    "    rng=np.random.default_rng()\n",
    "    random_state=int(rng.integers(low=low,high=high))\n",
    "    return random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df08b11b-44df-4634-8511-a25455ec4275",
   "metadata": {
    "id": "df08b11b-44df-4634-8511-a25455ec4275"
   },
   "outputs": [],
   "source": [
    "def get_variable_name(var):\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    return [name for name, val in callers_local_vars if val is var]\n",
    "\n",
    "def fileDaterSaver(location: str,\n",
    "                   filetype: str,\n",
    "                   object_,\n",
    "                   extra: str = '',\n",
    "                   verbose: bool = True):\n",
    "\n",
    "    '''\n",
    "    Function that gets a timestamped filename and saves it\n",
    "    to a user-specified location.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    location: str - The location where the file will be saved.\n",
    "    filetype: str - The type of the file to save ('csv' or 'json').\n",
    "    object_: The object to be saved. Should be a pandas DataFrame\n",
    "        for 'csv' or serializable for 'json'.\n",
    "    extra: str - Additional string to include in the filename.\n",
    "    verbose: bool - Whether to print verbose messages.\n",
    "    '''\n",
    "\n",
    "    # get current date and time\n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # print current date and time to check\n",
    "    if verbose:\n",
    "        print('current_datetime:', current_datetime)\n",
    "\n",
    "    # format the datetime for a filename\n",
    "    datetime_suffix = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # create filename with the datetime suffix\n",
    "    if extra != '':\n",
    "        file_name = f'{location}{extra}_{datetime_suffix}.{filetype}'\n",
    "    else:\n",
    "        file_name = f'{location}{datetime_suffix}.{filetype}'\n",
    "\n",
    "    # print file name\n",
    "    if verbose:\n",
    "        print(file_name)\n",
    "\n",
    "    # save object\n",
    "    if filetype == 'csv':\n",
    "        object_.to_csv(file_name, index=True)\n",
    "    elif filetype == 'json':\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(json.dumps(object_, default=str))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use 'csv' or 'json'.\")\n",
    "\n",
    "    # confirm save\n",
    "    file_path = Path(file_name)\n",
    "    if file_path.exists():\n",
    "        variable_name = get_variable_name(object_)\n",
    "        if variable_name:\n",
    "            print(f'Successfully saved {variable_name[0]} to {file_path}')\n",
    "        else:\n",
    "            print(f'Successfully saved object to {file_path}')\n",
    "    else:\n",
    "        print(\"File save error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "QJuJyOSRMAio",
   "metadata": {
    "id": "QJuJyOSRMAio"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7387"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=rand_gen()\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "w1DRWNJkMCZw",
   "metadata": {
    "id": "w1DRWNJkMCZw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size=0.2\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9497aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "df=pd.read_csv('/content/drive/MyDrive/2_data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url=''\n",
    "# df=pd.read_csv(url)\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not in Google Colab:\n",
    "\n",
    "# read in data\n",
    "df=pd.read_csv('../data/2_data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b284f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U -q PyDrive2\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# # Authenticate and create the PyDrive client.\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8daf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "link='https://drive.google.com/file/d/1uIUzYWMQA_hl1odTnBTfwCV4m8K8BqMt/view?usp=share_link'\n",
    "df=pd.read_csv(link)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76590fed-93ce-44de-bc02-ad395a92a8ad",
   "metadata": {
    "id": "76590fed-93ce-44de-bc02-ad395a92a8ad"
   },
   "source": [
    "## EDA <a name='eda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ed000-fd7a-4eea-beb2-47dfd641e158",
   "metadata": {
    "id": "f41ed000-fd7a-4eea-beb2-47dfd641e158"
   },
   "source": [
    "### Non-visual data analysis <a name='neda'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fLmFQtkSBxS",
   "metadata": {
    "id": "2fLmFQtkSBxS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ubeWT8CMcsgV",
   "metadata": {
    "id": "ubeWT8CMcsgV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-eEx0DSkIeBH",
   "metadata": {
    "id": "-eEx0DSkIeBH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44e2a9a-5663-41f3-a4a6-3a5da75e8a70",
   "metadata": {
    "id": "a44e2a9a-5663-41f3-a4a6-3a5da75e8a70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "\n",
       "   contact  day month  duration  campaign   y  \n",
       "0  unknown    5   may       261         1  no  \n",
       "1  unknown    5   may       151         1  no  \n",
       "2  unknown    5   may        76         1  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fkMqzVSuJB-u",
   "metadata": {
    "id": "fkMqzVSuJB-u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jqy_J5D4JDmh",
   "metadata": {
    "id": "jqy_J5D4JDmh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d504d8-387b-48ad-b38c-cd9643008132",
   "metadata": {
    "id": "19d504d8-387b-48ad-b38c-cd9643008132"
   },
   "outputs": [],
   "source": [
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83dedcb-3dc4-42f4-82b7-6d2daccc6e16",
   "metadata": {
    "id": "a83dedcb-3dc4-42f4-82b7-6d2daccc6e16"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564bfb5-45dd-4033-b764-8f501f328b08",
   "metadata": {
    "id": "1564bfb5-45dd-4033-b764-8f501f328b08"
   },
   "source": [
    "There are no nulls in the dataset, which makes our lives easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9356447-d016-4849-9e8c-3de5ad279bec",
   "metadata": {
    "id": "a9356447-d016-4849-9e8c-3de5ad279bec"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a3834-46d1-4b26-8066-ab68d3117545",
   "metadata": {
    "id": "597a3834-46d1-4b26-8066-ab68d3117545"
   },
   "source": [
    "We can glean the following insights from this table:\n",
    "* The mean values for the `age`, `day`, and `campaign` columns are about equal to the 50th percentile\n",
    "  * The distribution of the data may be symmetric\n",
    "* The max value in each column besides `age` and `day` is much larger than the column's 75th percentile\n",
    "  * This suggests there could be outliers\n",
    "  * `age` and `day` are more or less categorical, so it makes sense that the max age is 95 and max day is 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3d672-3180-4ce0-9cf9-c07e30bfd2b3",
   "metadata": {
    "id": "e3b3d672-3180-4ce0-9cf9-c07e30bfd2b3"
   },
   "source": [
    "What if we compare the subset of the data that had a positive `y` outcome to those that had a negative outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fadeaa-2aa6-4033-a3dc-9d0269561a6b",
   "metadata": {
    "id": "b0fadeaa-2aa6-4033-a3dc-9d0269561a6b"
   },
   "outputs": [],
   "source": [
    "# customers in the dataset who did get a loan\n",
    "df_yes = df[df['y'] == 'yes']\n",
    "df_yes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f73fe0-ffaa-4e07-beb1-c3080457c670",
   "metadata": {
    "id": "c7f73fe0-ffaa-4e07-beb1-c3080457c670"
   },
   "outputs": [],
   "source": [
    "# customers in the dataset who did not get a loan\n",
    "df_no = df[df['y'] == 'no']\n",
    "df_no.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7587127e-3db7-4a67-a65c-63237f4af0df",
   "metadata": {
    "id": "7587127e-3db7-4a67-a65c-63237f4af0df",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{df_yes.shape[0]/df.shape[0]*100}% of the dataset has positive outcomes, while {round(df_no.shape[0]/df.shape[0]*100,2)}% of the dataset has negative outcomes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f974863f-76db-4773-9839-d9c484e5e894",
   "metadata": {
    "id": "f974863f-76db-4773-9839-d9c484e5e894"
   },
   "source": [
    "We can see:\n",
    "* There is a large class imbalance in the dataset\n",
    "* The mean values are roughly the same across the numerical columns and loan outcomes\n",
    "  * Except for duration, which is about 3x as less for calls that don't end with a sale (`y`=no)\n",
    "* The max values for `balance` and `campaign` are about 2.25x and 2x as large for `y`=no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7a575-229e-41b7-970a-56ba745dbc97",
   "metadata": {
    "id": "b3a7a575-229e-41b7-970a-56ba745dbc97"
   },
   "source": [
    "Let's do some more aggregations to tease apart the differences between the different classes within each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a7fcd-0329-415b-9450-123a23bfa83b",
   "metadata": {
    "id": "236a7fcd-0329-415b-9450-123a23bfa83b"
   },
   "outputs": [],
   "source": [
    "# functions to compute the quantiles\n",
    "\n",
    "def q25(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def q50(x):\n",
    "    return x.quantile(0.50)\n",
    "\n",
    "def q75(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "def iqr(x):\n",
    "    return q75(x)-q25(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe019bd7-5270-4831-b5a4-c504bfbc602e",
   "metadata": {
    "id": "fe019bd7-5270-4831-b5a4-c504bfbc602e"
   },
   "source": [
    "We can edit this code to slice and dice the dataset as we please:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9287ad-91c4-4697-b903-1bb96c89a0f5",
   "metadata": {
    "id": "bf9287ad-91c4-4697-b903-1bb96c89a0f5"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00aa490-c632-431a-96ae-ecf4b02aa847",
   "metadata": {
    "id": "b00aa490-c632-431a-96ae-ecf4b02aa847"
   },
   "outputs": [],
   "source": [
    "groupby_list=['count','mean','std','min',q25,q50,q75,iqr]\n",
    "df.groupby([\n",
    "    # 'age',\n",
    "    'job',\n",
    "    # 'marital',\n",
    "    # 'education',\n",
    "    # 'default',\n",
    "    # 'housing',\n",
    "    # 'loan',\n",
    "    # 'contact',\n",
    "    # 'day',\n",
    "    # 'month',\n",
    "    # 'y'\n",
    "]).agg(\n",
    "    {\n",
    "        'balance':groupby_list,\n",
    "        # 'duration':groupby_list,\n",
    "        # 'campaign':groupby_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757428b-b424-4040-8821-d7402a5af943",
   "metadata": {
    "id": "2757428b-b424-4040-8821-d7402a5af943"
   },
   "source": [
    "There are different mean balances depending on what job the customer is in, which is to be expected: a blue-collar worker is not typically making the same amount of money that someone in management makes, so the balance in their bank account would be different too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad59952-9dcc-47c9-9f1f-d6ec727b0eea",
   "metadata": {
    "id": "2ad59952-9dcc-47c9-9f1f-d6ec727b0eea"
   },
   "outputs": [],
   "source": [
    "# create dictionary of unique values\n",
    "dict_unique={col:df[col].nunique() for col in df.columns}\n",
    "\n",
    "# this is a little unwieldy\n",
    "# but it will give us a sense of\n",
    "# HOW MANY unique values there are\n",
    "dict_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acad808-277a-467f-a454-270c8b24b3ae",
   "metadata": {
    "id": "4acad808-277a-467f-a454-270c8b24b3ae"
   },
   "source": [
    "We can tell which columns are categorical. For example, there are...\n",
    "* 12 kinds of jobs\n",
    "* 4 education levels  \n",
    "\n",
    "...in the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086f5f9-4c66-47cc-b330-dde788394461",
   "metadata": {
    "id": "d086f5f9-4c66-47cc-b330-dde788394461"
   },
   "outputs": [],
   "source": [
    "# create dictionary of unique values\n",
    "dict_nunique={col:df[col].unique() for col in df.columns}\n",
    "\n",
    "# this is a little unwieldy\n",
    "# but it will give us a sense of\n",
    "# WHAT the unique values are\n",
    "dict_nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5c4f4-97ea-4763-a7d0-c196783eef0b",
   "metadata": {
    "id": "07c5c4f4-97ea-4763-a7d0-c196783eef0b"
   },
   "source": [
    "Nothing too surprising jumps out at us here, so we'll need to use more... _visual_ methods to understand the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9473f62-b437-4ccd-a13a-6dc1c53cb606",
   "metadata": {
    "id": "d9473f62-b437-4ccd-a13a-6dc1c53cb606"
   },
   "source": [
    "### Visualization <a name='viz'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba9795-a9e2-4175-9e2b-d68a0894a122",
   "metadata": {
    "id": "caba9795-a9e2-4175-9e2b-d68a0894a122"
   },
   "source": [
    "#### Figure 1: Barplots of Categorical features <a name='fig1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d8baf-a728-480e-bed8-8a3656431494",
   "metadata": {
    "id": "340d8baf-a728-480e-bed8-8a3656431494"
   },
   "source": [
    "Make a big figure with all the categorical features:\n",
    "* `job`\n",
    "* `marital`\n",
    "* `education`\n",
    "* `default`\n",
    "* `housing`\n",
    "* `loan`\n",
    "* `contact`\n",
    "* `day`\n",
    "* `month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c5bfa-e074-4b6e-8e70-a6394312b360",
   "metadata": {
    "id": "212c5bfa-e074-4b6e-8e70-a6394312b360"
   },
   "outputs": [],
   "source": [
    "# make dictionary of just the categorical variables\n",
    "cat_nunique=copy.deepcopy(dict_nunique)\n",
    "del cat_nunique['age']\n",
    "del cat_nunique['balance']\n",
    "del cat_nunique['duration']\n",
    "del cat_nunique['campaign']\n",
    "del cat_nunique['y']\n",
    "cat_nunique={key: sorted(value) for key, value in cat_nunique.items()}\n",
    "print(cat_nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e271b05-f4de-41e8-9b3d-37a87486284b",
   "metadata": {
    "id": "5e271b05-f4de-41e8-9b3d-37a87486284b"
   },
   "outputs": [],
   "source": [
    "job_order=list(df['job'].unique())\n",
    "job_order.sort()\n",
    "job_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0d0a6-b04e-4486-bdd5-ae41d473b547",
   "metadata": {
    "id": "b7e0d0a6-b04e-4486-bdd5-ae41d473b547"
   },
   "outputs": [],
   "source": [
    "cat_nunique['month']=['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07670898-d8cd-4732-86b8-82edb3936355",
   "metadata": {
    "id": "07670898-d8cd-4732-86b8-82edb3936355",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get total number of plots\n",
    "num_plots=len(cat_nunique)*2\n",
    "\n",
    "# create subplots\n",
    "fig,axes=plt.subplots(num_plots,1,figsize=(15,num_plots*4))\n",
    "plt.suptitle(t='Counts of Categorical Variables in Dataset',y=.999)\n",
    "plt.tight_layout()\n",
    "\n",
    "# flatten axes for easy indexing\n",
    "axes=axes.flatten()\n",
    "\n",
    "# plot each column\n",
    "for i, (col, order) in enumerate(cat_nunique.items()):\n",
    "#     plot 'no' part\n",
    "    ax1=sns.countplot(data=df_no,x=col,palette='colorblind', dodge=True, order=order,ax=axes[i*2])\n",
    "    # ax1.set_title(f'{col.capitalize()} Distribution for Failed Campaigns')\n",
    "    for p in ax1.patches:\n",
    "        ax1.annotate(format(p.get_height(), '.0f'),\n",
    "                     (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                     ha = 'center', va = 'center',\n",
    "                     xytext = (0, 4),\n",
    "                     textcoords = 'offset points')\n",
    "    ax1.text(ax1.get_xlim()[1]+(ax1.get_xlim()[1])*(-0.17),\n",
    "             ax1.get_ylim()[1] - (ax1.get_ylim()[1])*(1/5),\n",
    "             f'Variable: {col.capitalize()}\\nFailed Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    # Plot 'yes' part\n",
    "    ax2 = sns.countplot(data=df_yes,x=col,palette='colorblind',dodge=True,order=order,ax=axes[i*2 + 1])\n",
    "    # ax2.set_title(f'{col.capitalize()} Distribution for Successful Campaigns')\n",
    "    for p in ax2.patches:\n",
    "        ax2.annotate(format(p.get_height(), '.0f'),\n",
    "                     (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                     ha = 'center', va = 'center',\n",
    "                     xytext = (0, 4),\n",
    "                     textcoords = 'offset points')\n",
    "    ax2.text(ax2.get_xlim()[1]+(ax2.get_xlim()[1])*(-0.17),\n",
    "             ax2.get_ylim()[1] - (ax2.get_ylim()[1])*(1/5),\n",
    "             f'Variable: {col.capitalize()}\\nSuccessful Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "plt.savefig('../figs/2_countcategorical.pdf')\n",
    "plt.savefig('../figs/2_countcategorical.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37d543-09ab-4d80-bf8d-7f8355dcb426",
   "metadata": {
    "id": "ea37d543-09ab-4d80-bf8d-7f8355dcb426"
   },
   "source": [
    "There is a lot to observe here, but note that although the values differ drastically between successful and failed campaigns, the patterns are similar for most of the features.\n",
    "\n",
    "Also notable is that there were no calls made to customers in the month of September."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbb88a-6960-4990-8a2c-f61c47cd1d85",
   "metadata": {
    "id": "f4dbb88a-6960-4990-8a2c-f61c47cd1d85",
    "tags": []
   },
   "source": [
    "#### Figure 2: Histograms of Continuous Features <a name='fig2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1f847-89ac-4745-9879-389fe066976f",
   "metadata": {
    "id": "e5a1f847-89ac-4745-9879-389fe066976f"
   },
   "outputs": [],
   "source": [
    "# make dictionary of just the categorical variables\n",
    "num_nunique=copy.deepcopy(dict_nunique)\n",
    "del num_nunique['job']\n",
    "del num_nunique['marital']\n",
    "del num_nunique['education']\n",
    "del num_nunique['default']\n",
    "del num_nunique['housing']\n",
    "del num_nunique['loan']\n",
    "del num_nunique['contact']\n",
    "del num_nunique['day']\n",
    "del num_nunique['month']\n",
    "del num_nunique['y']\n",
    "num_nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0eb7e-185b-4761-b6b8-c3c37d2d6451",
   "metadata": {
    "id": "d9d0eb7e-185b-4761-b6b8-c3c37d2d6451"
   },
   "outputs": [],
   "source": [
    "# get total number of plots\n",
    "num_plots=len(num_nunique)*2\n",
    "\n",
    "# create subplots\n",
    "fig,axes=plt.subplots(num_plots,1,figsize=(15,num_plots*4))\n",
    "plt.suptitle(t='Histograms of Continuous Variables in Dataset',y=.999)\n",
    "plt.tight_layout()\n",
    "\n",
    "# flatten axes for easy indexing\n",
    "axes=axes.flatten()\n",
    "\n",
    "# plot each column\n",
    "for i, (col, order) in enumerate(num_nunique.items()):\n",
    "#     plot 'no' part\n",
    "    ax1=sns.histplot(data=df_no,x=col,color='cornflowerblue',ax=axes[i*2])\n",
    "    ax1.text(ax1.get_xlim()[1]+(ax1.get_xlim()[1])*(-0.17),\n",
    "             ax1.get_ylim()[1] - (ax1.get_ylim()[1])*(1/5),\n",
    "             f'Variable: {col.capitalize()}\\nFailed Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    # Plot 'yes' part\n",
    "    ax2 = sns.histplot(data=df_yes,x=col,color='orange',ax=axes[i*2 + 1])\n",
    "    ax2.text(ax2.get_xlim()[1]+(ax2.get_xlim()[1])*(-0.17),\n",
    "             ax2.get_ylim()[1] - (ax2.get_ylim()[1])*(1/5),\n",
    "             f'Variable: {col.capitalize()}\\nSuccessful Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "plt.savefig('../figs/2_histograms.pdf')\n",
    "plt.savefig('../figs/2_histograms.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7643e-ce07-403d-a077-1966119ffebd",
   "metadata": {
    "id": "dbd7643e-ce07-403d-a077-1966119ffebd"
   },
   "source": [
    "The patterns between successful and failed campaigns' continuous data are mostly similar, although the X and Y axes are different. The one feature that I see is different is the distribution for duration for successful campaigns is wider than those for failed campaigns. Boxplots may clear this up for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd34308-3f68-4981-be99-a8b7fd88cbaf",
   "metadata": {
    "id": "6bd34308-3f68-4981-be99-a8b7fd88cbaf"
   },
   "source": [
    "#### Figure 3: Boxplots of Continuous Features <a name='fig3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ZFtzdk3cEni",
   "metadata": {
    "id": "8ZFtzdk3cEni"
   },
   "outputs": [],
   "source": [
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67605bbd-9f65-4074-95be-3d9ab480980f",
   "metadata": {
    "id": "67605bbd-9f65-4074-95be-3d9ab480980f"
   },
   "outputs": [],
   "source": [
    "# get total number of plots\n",
    "num_plots=len(num_nunique)*2\n",
    "\n",
    "# create subplots\n",
    "fig,axes=plt.subplots(num_plots,1,figsize=(15,num_plots*4))\n",
    "plt.suptitle(t='Histograms of Continuous Variables in Dataset',y=.999)\n",
    "plt.tight_layout()\n",
    "\n",
    "# flatten axes for easy indexing\n",
    "axes=axes.flatten()\n",
    "\n",
    "# plot each column\n",
    "for i, (col, order) in enumerate(num_nunique.items()):\n",
    "#     plot 'no' part\n",
    "    ax1=sns.boxplot(data=df_no,x=col,color='cornflowerblue',ax=axes[i*2])\n",
    "    ax1.text(ax1.get_xlim()[1]+(ax1.get_xlim()[1])*(-0.17),\n",
    "             ax1.get_ylim()[1] - (ax1.get_ylim()[1])*(1/5),\n",
    "             f'Variable: {col.capitalize()}\\nFailed Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    # Plot 'yes' part\n",
    "    ax2 = sns.boxplot(data=df_yes,x=col,color='orange',ax=axes[i*2 + 1])\n",
    "    ax2.text(ax2.get_xlim()[1]+(ax2.get_xlim()[1])*(-0.17),\n",
    "             ax2.get_ylim()[1] - (ax2.get_ylim()[1])*(1/5),\n",
    "             f'Variable: {col.capitalize()}\\nSuccessful Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "plt.savefig('../figs/2_boxplots.pdf')\n",
    "plt.savefig('../figs/2_boxplots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a04bc5-2031-4ea0-bb28-7755e4bb3bd5",
   "metadata": {
    "id": "b3a04bc5-2031-4ea0-bb28-7755e4bb3bd5"
   },
   "source": [
    "Duration does indeed seem different, though recall that this feature is describing how long the last phone call was with the customer. It may not tell us that much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd63d0-5316-4191-8db6-56bdc3287b92",
   "metadata": {
    "id": "b1cd63d0-5316-4191-8db6-56bdc3287b92"
   },
   "source": [
    "#### Figure 4: Correlation Matrix of Continuous Features <a name='fig4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97L7Q0-CeTsx",
   "metadata": {
    "id": "97L7Q0-CeTsx"
   },
   "outputs": [],
   "source": [
    "df_num=df[['age','balance','duration','campaign']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4a708-bff3-41b2-b23d-ef5e6c4f1915",
   "metadata": {
    "id": "f0d4a708-bff3-41b2-b23d-ef5e6c4f1915"
   },
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "corr=df_num[['age','balance','duration','campaign']].corr()\n",
    "\n",
    "# generate mask for the upper triangle\n",
    "mask=np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# set up matplotlib figure\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "# draw heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr,mask=mask,cmap='coolwarm',#vmax=1,vmin=-1,\n",
    "            center=0,\n",
    "            square=True,linewidths=.5,annot=True,\n",
    "            fmt='.2f',cbar_kws={\"shrink\":.5})\n",
    "plt.title('Correlation Matrix of Numerical Features\\n$Higher$ $absolute$ $value$ $indicates$ $stronger$ $correlation$')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save fig\n",
    "plt.savefig('../figs/2_corrmatrix_num.pdf')\n",
    "plt.savefig('../figs/2_corrmatrix_num.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b1ee8-e1cb-4988-b177-a2d28e110835",
   "metadata": {
    "id": "7e8b1ee8-e1cb-4988-b177-a2d28e110835"
   },
   "source": [
    "It's good to see that there are no strong correlations with the numerical data. `age`:`balance` makes sense because as you age, you will have had a longer time to accrue more money.\n",
    "\n",
    "Let's now look at the categorical data now:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923b60d-bf3a-499e-aca9-f8be92dd445f",
   "metadata": {
    "id": "f923b60d-bf3a-499e-aca9-f8be92dd445f"
   },
   "source": [
    "#### Figure 5: Correlation Matrix of Categorical Features <a name='fig5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072151f8-7ceb-438e-90c0-91dbc531e3f0",
   "metadata": {
    "id": "072151f8-7ceb-438e-90c0-91dbc531e3f0"
   },
   "outputs": [],
   "source": [
    "# make a df of just the categorical values\n",
    "df_cat=df[['job','marital','education','default','housing','loan','contact','day','month','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9383c3-0de4-4d65-b072-60dcc38b5c77",
   "metadata": {
    "id": "4e9383c3-0de4-4d65-b072-60dcc38b5c77"
   },
   "outputs": [],
   "source": [
    "def cramers_v(x, y):\n",
    "    \"\"\"Calculate Cramér's V statistic for categorical-categorical association.\"\"\"\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1)) / (n-1))\n",
    "    rcorr = r - ((r-1)**2) / (n-1)\n",
    "    kcorr = k - ((k-1)**2) / (n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "def cramers_v_matrix(df):\n",
    "    \"\"\"Compute a matrix of Cramér's V statistics for all pairs of categorical columns in a DataFrame.\"\"\"\n",
    "    cols = df.columns\n",
    "    n = len(cols)\n",
    "    cv_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cv_matrix[i, j] = cramers_v(df[cols[i]], df[cols[j]])\n",
    "    return pd.DataFrame(cv_matrix, index=cols, columns=cols)\n",
    "\n",
    "# Compute Cramér's V matrix\n",
    "cv_matrix = cramers_v_matrix(df_cat)\n",
    "\n",
    "# generate mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(cv_matrix, dtype=bool))\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cv_matrix, annot=True, cmap='coolwarm', #vmin=-1, vmax=1,\n",
    "            mask=mask, cbar_kws={\"shrink\": .8},fmt='.2f')\n",
    "\n",
    "plt.title(\"Cramér's V Correlation Matrix\")\n",
    "\n",
    "# save fig\n",
    "plt.savefig('../figs/2_corrmatrix_categorical.pdf')\n",
    "plt.savefig('../figs/2_corrmatrix_categorical.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090a3916-3a58-47f1-93f9-a6a49d0589c3",
   "metadata": {
    "id": "090a3916-3a58-47f1-93f9-a6a49d0589c3"
   },
   "source": [
    "This is a great figure. Most correlations are very slight, but there are a few stronger correlations, like `contact`:`month`, `housing`:`month`, `job`:`education`, and `day`:`month`. These correlations mostly make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2af0ec-16d5-4dc6-a7c0-928a617684e1",
   "metadata": {
    "id": "ff2af0ec-16d5-4dc6-a7c0-928a617684e1"
   },
   "source": [
    "#### What about Scatterplots? <a name='scat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4cfff-4714-49de-99cb-6c0ac9b893fa",
   "metadata": {
    "id": "16a4cfff-4714-49de-99cb-6c0ac9b893fa"
   },
   "source": [
    "Scatterplots do not seem to give us much insight. The data points are very dispersed and a pattern does not readily emerge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20060ed-668c-4988-8ca7-073425715e8a",
   "metadata": {
    "id": "f20060ed-668c-4988-8ca7-073425715e8a"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=df,hue='y')\n",
    "\n",
    "plt.savefig('../figs/2_pairplot.pdf')\n",
    "plt.savefig('../figs/2_pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c178b-eed7-44e0-a5e4-6d3e5b23b46e",
   "metadata": {
    "id": "0d7c178b-eed7-44e0-a5e4-6d3e5b23b46e"
   },
   "outputs": [],
   "source": [
    "# reinstate warning labels\n",
    "import warnings\n",
    "warnings.filterwarnings(\"default\", module=\"seaborn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ad854-c659-4b08-81cb-323863e3497d",
   "metadata": {
    "id": "af1ad854-c659-4b08-81cb-323863e3497d"
   },
   "source": [
    "## Modeling <a name='mod'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62bb50a-ec4b-4158-afe0-8ceacd187620",
   "metadata": {
    "id": "c62bb50a-ec4b-4158-afe0-8ceacd187620"
   },
   "source": [
    "### Goals recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed783d3-f06d-4ffb-b0cc-28048bb44f6a",
   "metadata": {
    "id": "eed783d3-f06d-4ffb-b0cc-28048bb44f6a"
   },
   "source": [
    "To achieve this project's goals, we have to run models. As a reminder, this project is aiming to predict customer behavior. Specifically, we are training models to determine if a customer will buy a term deposit loan.\n",
    "\n",
    "We are aiming to achieve ≥81% accuracy with the modeling\n",
    "  * Use a 5-fold cross validation strategy and take the average performance score.\n",
    "\n",
    "Bonus goals include:\n",
    "* Determine which customers are most likely to buy the term deposit loan\n",
    "  * Which segments of customers should the client prioritize?\n",
    "* Determine what makes the customer buy the loan\n",
    "  * Which feature should the startup focus on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c05809-2f22-425d-9618-5c7b7df828d0",
   "metadata": {
    "id": "95c05809-2f22-425d-9618-5c7b7df828d0"
   },
   "source": [
    "### PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f9fdb-8d4c-4d16-9058-0d2978d9cbea",
   "metadata": {
    "id": "217f9fdb-8d4c-4d16-9058-0d2978d9cbea"
   },
   "source": [
    "[PyCaret](#https://pycaret.gitbook.io/docs) is a library that helps make it easy to experiment on the performance of different ML algorithms so that we can maximize our time on optimizing the best algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lJoByLapP3LI",
   "metadata": {
    "id": "lJoByLapP3LI"
   },
   "source": [
    "Classification using the OOP syntax, building on the example from [pycaret.gitbook.io](#pycaret.gitbook.io):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dz0RebMIUOLd",
   "metadata": {
    "id": "dz0RebMIUOLd"
   },
   "source": [
    "The results of PyCaret show that Gradient Boosting Classifier gave the best accuracy, at almost 94%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84GnaFsqaMC0",
   "metadata": {
    "id": "84GnaFsqaMC0"
   },
   "outputs": [],
   "source": [
    "clf1 = setup(df,\n",
    "             target = 'y',\n",
    "             session_id=seed,\n",
    "             log_experiment=True,\n",
    "             experiment_name='clf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-hBd5OF-MOkw",
   "metadata": {
    "id": "-hBd5OF-MOkw"
   },
   "outputs": [],
   "source": [
    "# save setup results\n",
    "setup_results=pull()\n",
    "# print(setup_results)\n",
    "# setup_results.to_csv('../joblib/2_pycaret_setupresults.csv')\n",
    "from google.colab import files\n",
    "setup_results.to_csv('2_pycaret_setupresults.csv',encoding='utf-8-sig')\n",
    "files.download('2_pycaret_setupresults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jSktxcqybEHd",
   "metadata": {
    "id": "jSktxcqybEHd"
   },
   "outputs": [],
   "source": [
    "best_model=compare_models(fold=5)\n",
    "\n",
    "# save setup results\n",
    "# best_model.to_csv('../joblib/2_pycaret_bestmodel.csv')\n",
    "best_model=pull()\n",
    "best_model.to_csv('2_pycaret_bestmodel.csv',encoding='utf-8-sig')\n",
    "files.download('2_pycaret_bestmodel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dhmsEtaf-8z",
   "metadata": {
    "id": "8dhmsEtaf-8z"
   },
   "outputs": [],
   "source": [
    "gbc_model=create_model('gbc')\n",
    "\n",
    "# save gbc_model\n",
    "# gbc_model.pull()\n",
    "# gbc_model.to_csv('../joblib/2_pycaret_gbcmodel.csv')\n",
    "# gbc_model.to_csv('2_pycaret_gbcmodel.csv',encoding='utf-8-sig')\n",
    "# files.download('2_pycaret_gbcmodel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jEjqqvOLf9Qu",
   "metadata": {
    "id": "jEjqqvOLf9Qu"
   },
   "outputs": [],
   "source": [
    "feature_importances=plot_model(gbc_model,plot='feature',save=True)\n",
    "feature_importances=plot_model(gbc_model,plot='feature')\n",
    "# save feature_importances\n",
    "# feature_importances.pull()\n",
    "# feature_importances.to_csv('2_pycaret_featureimportances.csv',encoding='utf-8-sig')\n",
    "# files.download('2_pycaret_featureimportances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_Ims8R34ReXP",
   "metadata": {
    "id": "_Ims8R34ReXP"
   },
   "source": [
    "We see that according to PyCaret, `duration` has the strongest importance on predicting campaign success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o4ZZtOsxaSdL",
   "metadata": {
    "id": "o4ZZtOsxaSdL"
   },
   "outputs": [],
   "source": [
    "evaluate_model(gbc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LaL38jeJQduV",
   "metadata": {
    "id": "LaL38jeJQduV"
   },
   "outputs": [],
   "source": [
    "# plot AUC\n",
    "plot_model(gbc_model, plot = 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cyQNqrKXacmY",
   "metadata": {
    "id": "cyQNqrKXacmY"
   },
   "source": [
    "The AUC-ROC curve is looking pretty healthy: an AUC of over 90% is great. As this is just the base model, let's move to a more rigorous modeling strategy to help us answer this project's questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JsU0q3o6edcI",
   "metadata": {
    "id": "JsU0q3o6edcI"
   },
   "source": [
    "The results of the PyCaret experimentation show that the Gradient Boosting Classifier algorithm is best suited for the data. Let's use that for our modeling efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ixBSnhkXenpQ",
   "metadata": {
    "id": "ixBSnhkXenpQ"
   },
   "source": [
    "### Will a customer purchase a loan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yqZSxW3wfiCO",
   "metadata": {
    "id": "yqZSxW3wfiCO"
   },
   "source": [
    "To answer this question, we need to prepare the dataset so that we have a training and a testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c913e2a9-e265-41f9-9b22-60b5543bd439",
   "metadata": {
    "id": "c913e2a9-e265-41f9-9b22-60b5543bd439"
   },
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a5d71-8e66-4092-8953-ab60cd938908",
   "metadata": {
    "id": "094a5d71-8e66-4092-8953-ab60cd938908"
   },
   "source": [
    "##### Process categorical and continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f28206a-0bc3-48e0-8b6d-e012074144ca",
   "metadata": {
    "id": "9f28206a-0bc3-48e0-8b6d-e012074144ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "\n",
       "   contact  day month  duration  campaign   y  \n",
       "0  unknown    5   may       261         1  no  \n",
       "1  unknown    5   may       151         1  no  \n",
       "2  unknown    5   may        76         1  no  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ac08d5-f630-4a8b-b16d-2ccc961cdeaf",
   "metadata": {
    "id": "06ac08d5-f630-4a8b-b16d-2ccc961cdeaf"
   },
   "outputs": [],
   "source": [
    "# make copy to preserve our progress\n",
    "df_modeling=copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f692b-0db3-46d3-a82c-51c1efb98a3e",
   "metadata": {
    "id": "308f692b-0db3-46d3-a82c-51c1efb98a3e"
   },
   "source": [
    "First, let's convert some categorical columns to binary. This will help me keep track of my progress, as I'll be able to clearly see which columns still need to be processed. Some may need to be discretized, like `job` and `education`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92759d1a-513b-42fd-9ed9-a20a338b0170",
   "metadata": {
    "id": "92759d1a-513b-42fd-9ed9-a20a338b0170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan\n",
       "no     33070\n",
       "yes     6930\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling['loan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3bc590-1656-4454-a53c-1a617e1cc301",
   "metadata": {
    "id": "5c3bc590-1656-4454-a53c-1a617e1cc301"
   },
   "outputs": [],
   "source": [
    "df_modeling['y']=df_modeling['y'].map({'yes': 1, 'no': 0})\n",
    "df_modeling['default']=df_modeling['default'].map({'yes': 1, 'no': 0})\n",
    "df_modeling['housing']=df_modeling['housing'].map({'yes': 1, 'no': 0})\n",
    "df_modeling['loan']=df_modeling['loan'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c31d5b0-c5c2-402e-a72f-7633f7833ba6",
   "metadata": {
    "id": "6c31d5b0-c5c2-402e-a72f-7633f7833ba6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education  default  balance  housing  loan  \\\n",
       "0   58    management  married   tertiary        0     2143        1     0   \n",
       "1   44    technician   single  secondary        0       29        1     0   \n",
       "2   33  entrepreneur  married  secondary        0        2        1     1   \n",
       "\n",
       "   contact  day month  duration  campaign  y  \n",
       "0  unknown    5   may       261         1  0  \n",
       "1  unknown    5   may       151         1  0  \n",
       "2  unknown    5   may        76         1  0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235810b4-657a-42ef-ac9c-6d4d8cad011d",
   "metadata": {
    "id": "235810b4-657a-42ef-ac9c-6d4d8cad011d"
   },
   "source": [
    "Those are all the binary features. We still have to get the continuous variables separated and have to discretize, or \"OneHotEncode\" the rest of the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c61393c-0bf1-407d-a31e-60ef95606c95",
   "metadata": {
    "id": "9c61393c-0bf1-407d-a31e-60ef95606c95"
   },
   "outputs": [],
   "source": [
    "# define the categorical columns\n",
    "cat_cols=['job','marital','education','default','housing','loan','contact','month']\n",
    "df_cat=df_modeling[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35316033-6e65-4a5f-98ca-21a306793995",
   "metadata": {
    "id": "35316033-6e65-4a5f-98ca-21a306793995"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job  marital  education  default  housing  loan  contact month\n",
       "0    management  married   tertiary        0        1     0  unknown   may\n",
       "1    technician   single  secondary        0        1     0  unknown   may\n",
       "2  entrepreneur  married  secondary        0        1     1  unknown   may"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01a0e290-af10-482d-9a75-ecb73ec4e181",
   "metadata": {
    "id": "01a0e290-af10-482d-9a75-ecb73ec4e181"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2143</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign  balance  day  age  duration\n",
       "0         1     2143    5   58       261\n",
       "1         1       29    5   44       151\n",
       "2         1        2    5   33        76"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dataframe of continuous variables\n",
    "\n",
    "# set of categorical columns\n",
    "df_cat_set = set(df_cat.columns)\n",
    "# set of all columns\n",
    "df_modeling_set = set(df_modeling.columns)\n",
    "\n",
    "# Find columns that are in df_modeling but not in df_cat\n",
    "difference = df_modeling_set - df_cat_set\n",
    "\n",
    "# Convert the set to list and name it the continuous\n",
    "cont_cols = list(difference)\n",
    "cont_cols.remove('y')\n",
    "\n",
    "# print(\"Columns in DataFrame but not in the list:\\n\",cont_cols)\n",
    "\n",
    "df_cont=df_modeling[cont_cols]\n",
    "df_cont.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3302f05b-04cf-47e3-867d-5425fc80986d",
   "metadata": {
    "id": "3302f05b-04cf-47e3-867d-5425fc80986d"
   },
   "outputs": [],
   "source": [
    "# convert the categorical columns to the 'category' type\n",
    "for col in df_cat.columns:\n",
    "    df_cat.loc[:,col] = df_cat[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b95a7b-0e2c-406f-801b-b0105920d931",
   "metadata": {
    "id": "53b95a7b-0e2c-406f-801b-b0105920d931"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job  marital  education  default  housing  loan  contact month\n",
       "0    management  married   tertiary        0        1     0  unknown   may\n",
       "1    technician   single  secondary        0        1     0  unknown   may\n",
       "2  entrepreneur  married  secondary        0        1     1  unknown   may"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "417f155a-4be8-4a70-abae-b83c39ac9b2c",
   "metadata": {
    "id": "417f155a-4be8-4a70-abae-b83c39ac9b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   job_blue-collar      40000 non-null  int64\n",
      " 1   job_entrepreneur     40000 non-null  int64\n",
      " 2   job_housemaid        40000 non-null  int64\n",
      " 3   job_management       40000 non-null  int64\n",
      " 4   job_retired          40000 non-null  int64\n",
      " 5   job_self-employed    40000 non-null  int64\n",
      " 6   job_services         40000 non-null  int64\n",
      " 7   job_student          40000 non-null  int64\n",
      " 8   job_technician       40000 non-null  int64\n",
      " 9   job_unemployed       40000 non-null  int64\n",
      " 10  job_unknown          40000 non-null  int64\n",
      " 11  marital_married      40000 non-null  int64\n",
      " 12  marital_single       40000 non-null  int64\n",
      " 13  education_secondary  40000 non-null  int64\n",
      " 14  education_tertiary   40000 non-null  int64\n",
      " 15  education_unknown    40000 non-null  int64\n",
      " 16  contact_telephone    40000 non-null  int64\n",
      " 17  contact_unknown      40000 non-null  int64\n",
      " 18  month_aug            40000 non-null  int64\n",
      " 19  month_dec            40000 non-null  int64\n",
      " 20  month_feb            40000 non-null  int64\n",
      " 21  month_jan            40000 non-null  int64\n",
      " 22  month_jul            40000 non-null  int64\n",
      " 23  month_jun            40000 non-null  int64\n",
      " 24  month_mar            40000 non-null  int64\n",
      " 25  month_may            40000 non-null  int64\n",
      " 26  month_nov            40000 non-null  int64\n",
      " 27  month_oct            40000 non-null  int64\n",
      "dtypes: int64(28)\n",
      "memory usage: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "# discretize the categorical columns\n",
    "already_encoded=['default','housing','loan','day']\n",
    "columns_to_encode = [col for col in df_cat.columns if col not in already_encoded]\n",
    "prefixes=columns_to_encode\n",
    "\n",
    "# apply get_dummies\n",
    "df_cat=pd.get_dummies(data=df_cat[columns_to_encode],prefix=prefixes,drop_first=True,dtype='int')\n",
    "\n",
    "# confirm\n",
    "df_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c9aaa8f-d6b0-4c27-8318-893cff9d93f9",
   "metadata": {
    "id": "5c9aaa8f-d6b0-4c27-8318-893cff9d93f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 33 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   job_blue-collar      40000 non-null  int64\n",
      " 1   job_entrepreneur     40000 non-null  int64\n",
      " 2   job_housemaid        40000 non-null  int64\n",
      " 3   job_management       40000 non-null  int64\n",
      " 4   job_retired          40000 non-null  int64\n",
      " 5   job_self-employed    40000 non-null  int64\n",
      " 6   job_services         40000 non-null  int64\n",
      " 7   job_student          40000 non-null  int64\n",
      " 8   job_technician       40000 non-null  int64\n",
      " 9   job_unemployed       40000 non-null  int64\n",
      " 10  job_unknown          40000 non-null  int64\n",
      " 11  marital_married      40000 non-null  int64\n",
      " 12  marital_single       40000 non-null  int64\n",
      " 13  education_secondary  40000 non-null  int64\n",
      " 14  education_tertiary   40000 non-null  int64\n",
      " 15  education_unknown    40000 non-null  int64\n",
      " 16  contact_telephone    40000 non-null  int64\n",
      " 17  contact_unknown      40000 non-null  int64\n",
      " 18  month_aug            40000 non-null  int64\n",
      " 19  month_dec            40000 non-null  int64\n",
      " 20  month_feb            40000 non-null  int64\n",
      " 21  month_jan            40000 non-null  int64\n",
      " 22  month_jul            40000 non-null  int64\n",
      " 23  month_jun            40000 non-null  int64\n",
      " 24  month_mar            40000 non-null  int64\n",
      " 25  month_may            40000 non-null  int64\n",
      " 26  month_nov            40000 non-null  int64\n",
      " 27  month_oct            40000 non-null  int64\n",
      " 28  campaign             40000 non-null  int64\n",
      " 29  balance              40000 non-null  int64\n",
      " 30  day                  40000 non-null  int64\n",
      " 31  age                  40000 non-null  int64\n",
      " 32  duration             40000 non-null  int64\n",
      "dtypes: int64(33)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "# add the continuous and categorical columns together\n",
    "df_x=pd.concat([df_cat,df_cont],axis=1)\n",
    "df_x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65843804-880d-4caf-b6ca-fcd4cfb6c298",
   "metadata": {
    "id": "65843804-880d-4caf-b6ca-fcd4cfb6c298"
   },
   "source": [
    "##### Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e6be7a2-09a3-4bef-a3fa-e77fb4751bc0",
   "metadata": {
    "id": "3e6be7a2-09a3-4bef-a3fa-e77fb4751bc0"
   },
   "outputs": [],
   "source": [
    "X=df_x\n",
    "y=df_modeling[[col for col in df_modeling.columns if col == 'y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebecde7d-2f95-4cf4-ab5e-8088adbc5045",
   "metadata": {
    "id": "ebecde7d-2f95-4cf4-ab5e-8088adbc5045"
   },
   "source": [
    "##### `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a378f9a0-f7ee-4520-b96d-8b209b207791",
   "metadata": {
    "id": "a378f9a0-f7ee-4520-b96d-8b209b207791"
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, \\\n",
    "X_test, \\\n",
    "y_train, \\\n",
    "y_test = train_test_split(X,\n",
    "                          y,\n",
    "                          test_size=test_size,\n",
    "                          stratify=y,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5rra9G9Nf92y",
   "metadata": {
    "id": "5rra9G9Nf92y"
   },
   "source": [
    "Now we have the dataset ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "PCdNmR3ZhIeW",
   "metadata": {
    "id": "PCdNmR3ZhIeW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 33 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   job_blue-collar      40000 non-null  int64\n",
      " 1   job_entrepreneur     40000 non-null  int64\n",
      " 2   job_housemaid        40000 non-null  int64\n",
      " 3   job_management       40000 non-null  int64\n",
      " 4   job_retired          40000 non-null  int64\n",
      " 5   job_self-employed    40000 non-null  int64\n",
      " 6   job_services         40000 non-null  int64\n",
      " 7   job_student          40000 non-null  int64\n",
      " 8   job_technician       40000 non-null  int64\n",
      " 9   job_unemployed       40000 non-null  int64\n",
      " 10  job_unknown          40000 non-null  int64\n",
      " 11  marital_married      40000 non-null  int64\n",
      " 12  marital_single       40000 non-null  int64\n",
      " 13  education_secondary  40000 non-null  int64\n",
      " 14  education_tertiary   40000 non-null  int64\n",
      " 15  education_unknown    40000 non-null  int64\n",
      " 16  contact_telephone    40000 non-null  int64\n",
      " 17  contact_unknown      40000 non-null  int64\n",
      " 18  month_aug            40000 non-null  int64\n",
      " 19  month_dec            40000 non-null  int64\n",
      " 20  month_feb            40000 non-null  int64\n",
      " 21  month_jan            40000 non-null  int64\n",
      " 22  month_jul            40000 non-null  int64\n",
      " 23  month_jun            40000 non-null  int64\n",
      " 24  month_mar            40000 non-null  int64\n",
      " 25  month_may            40000 non-null  int64\n",
      " 26  month_nov            40000 non-null  int64\n",
      " 27  month_oct            40000 non-null  int64\n",
      " 28  campaign             40000 non-null  int64\n",
      " 29  balance              40000 non-null  int64\n",
      " 30  day                  40000 non-null  int64\n",
      " 31  age                  40000 non-null  int64\n",
      " 32  duration             40000 non-null  int64\n",
      "dtypes: int64(33)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771b63c-41ae-4a1e-bf69-8dc0eafe9ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad79f2c-d84f-4c16-ad6f-3841ab704f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "\n",
       "   contact  day month  duration  campaign   y  \n",
       "0  unknown    5   may       261         1  no  \n",
       "1  unknown    5   may       151         1  no  \n",
       "2  unknown    5   may        76         1  no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c7ebe-261c-4a52-b9ea-4ae5f5d24143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad88586-6801-42fe-8061-1a9cf60fdaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "X="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e7c53-55f1-4a54-9402-f6ed6ad411c5",
   "metadata": {},
   "source": [
    "#### `Optuna`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e88245-9e9c-427a-8fa8-630c4daafa41",
   "metadata": {},
   "source": [
    "In order to find the best hyperparameters for our modeling, we will be using [Optuna](#https://optuna.readthedocs.io/en/stable/index.html). This is similar to other frameworks like [Hyperopt](#http://hyperopt.github.io/hyperopt/), which are designed to quickly and efficiently find the best hyperparameters for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fff9b-2926-4f7f-89ff-3e595a7e06ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f138f96-af18-4726-9128-b363a770b452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf241ab0-c158-48c0-b292-2a263cccc136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_U6PPzqXjnAQ",
   "metadata": {
    "id": "_U6PPzqXjnAQ"
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a pipeline with the preprocessor and the classifier\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GradientBoostingClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')\n",
    "    # Return the negative mean of the scores as we want to minimize the objective\n",
    "    return {'loss': -scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 300)),\n",
    "    'max_depth': hp.choice('max_depth', range(3, 15)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 10)),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GU7UL3atlCeB",
   "metadata": {
    "id": "GU7UL3atlCeB"
   },
   "source": [
    "We'll be making a pipeline that includes a preprocessor to handle features that need to be scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BnDw9Kbraa_J",
   "metadata": {
    "id": "BnDw9Kbraa_J"
   },
   "outputs": [],
   "source": [
    "# first, separate categorical from continuous features\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "continuous_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print('features separated')\n",
    "\n",
    "# create pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "print('preprocessor created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FadS144YlJ5z",
   "metadata": {
    "id": "FadS144YlJ5z"
   },
   "source": [
    "Then, using the parameters `hyperopt` found, we'll train the model and test its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ryrOuFZZjqJ2",
   "metadata": {
    "id": "ryrOuFZZjqJ2"
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'n_estimators': range(50, 300)[best['n_estimators']],\n",
    "    'max_depth': range(3, 15)[best['max_depth']],\n",
    "    'min_samples_split': range(2, 10)[best['min_samples_split']],\n",
    "    'min_samples_leaf': range(1, 10)[best['min_samples_leaf']],\n",
    "    'subsample': best['subsample']\n",
    "}\n",
    "\n",
    "# Create a pipeline with the preprocessor and the classifier\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(**best_params))\n",
    "])\n",
    "print('model created')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "print('model trained')\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6JcOYD-AkF1z",
   "metadata": {
    "id": "6JcOYD-AkF1z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beab20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18efef65",
   "metadata": {},
   "source": [
    "## Sklearn, AutoSklearn, Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484273dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chatgpt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import autosklearn.classification\n",
    "import optuna\n",
    "from optuna.integration import SklearnPruningCallback\n",
    "\n",
    "# Create a synthetic dataset\n",
    "data = {\n",
    "    'age': [25, 32, 47, 51, 62, 20, 27, 40, 34, 55],\n",
    "    'salary': [50000, 60000, 120000, 85000, 95000, 40000, 45000, 80000, 75000, 90000],\n",
    "    'gender': ['male', 'female', 'female', 'male', 'male', 'female', 'female', 'male', 'male', 'female'],\n",
    "    'bought_insurance': [0, 1, 1, 0, 1, 0, 0, 1, 1, 1]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop('bought_insurance', axis=1)\n",
    "y = df['bought_insurance']\n",
    "\n",
    "# Identify categorical and continuous columns\n",
    "categorical_cols = ['gender']\n",
    "continuous_cols = ['age', 'salary']\n",
    "\n",
    "# Preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Auto-sklearn classifier and pipeline\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=60, per_run_time_limit=30)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', automl)])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Auto-sklearn accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Define Optuna objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'ensemble_size': trial.suggest_int('ensemble_size', 10, 50),\n",
    "        'initial_configurations_via_metalearning': trial.suggest_int('initial_configurations_via_metalearning', 0, 25)\n",
    "    }\n",
    "    \n",
    "    automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "        time_left_for_this_task=60, per_run_time_limit=30, \n",
    "        ensemble_size=params['ensemble_size'], \n",
    "        initial_configurations_via_metalearning=params['initial_configurations_via_metalearning']\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', automl)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best hyperparameters: {study.best_params}\")\n",
    "\n",
    "# Use the best hyperparameters found by Optuna to fit and evaluate the final model\n",
    "best_params = study.best_params\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60, per_run_time_limit=30, \n",
    "    ensemble_size=best_params['ensemble_size'], \n",
    "    initial_configurations_via_metalearning=best_params['initial_configurations_via_metalearning']\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', automl)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final accuracy: {final_accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
