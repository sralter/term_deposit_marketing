{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sralter/term_deposit_marketing/blob/main/term_deposit_marketing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5227e004-7c3d-4d64-824d-36df80facdbf",
      "metadata": {
        "id": "5227e004-7c3d-4d64-824d-36df80facdbf"
      },
      "source": [
        "# Term Deposit Marketing - An Apziva Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13caaf73-d640-4bae-8ee1-f8b07ff73ed1",
      "metadata": {
        "id": "13caaf73-d640-4bae-8ee1-f8b07ff73ed1"
      },
      "source": [
        "By Samuel Alter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcc1066f-6628-43fc-abdb-fee10e55e68a",
      "metadata": {
        "id": "dcc1066f-6628-43fc-abdb-fee10e55e68a"
      },
      "source": [
        "Apziva: G3SuQYZYrFt9dwF3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9623536a-e44e-4fda-8dc5-0e5ed6282c62",
      "metadata": {
        "id": "9623536a-e44e-4fda-8dc5-0e5ed6282c62"
      },
      "source": [
        "## Project Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95b04356-770c-4b85-8823-5d6f7dec2f19",
      "metadata": {
        "id": "95b04356-770c-4b85-8823-5d6f7dec2f19"
      },
      "source": [
        "Using phone call data from a European bank, this project will be building a model that predicts if a customer will subscribe to a term deposit, a type of financial product. This project is a partnership with a startup focused on providing ML solutions for European banks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0523ee87-ca0b-4efc-80b1-86d7c3f5770f",
      "metadata": {
        "id": "0523ee87-ca0b-4efc-80b1-86d7c3f5770f",
        "tags": []
      },
      "source": [
        "### Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22534a75-16be-4d77-9a59-8f92436c1700",
      "metadata": {
        "id": "22534a75-16be-4d77-9a59-8f92436c1700"
      },
      "source": [
        "The startup is hoping that I can **achieve â‰¥81% accuracy** using a 5-fold cross validation strategy, taking the average performance score.\n",
        "\n",
        "Bonus goals include:\n",
        "* Determining which customers are most likely to buy the term deposit loan\n",
        "  * Which segments of customers should the client prioritize?\n",
        "* Determine what makes the customer buy the loan\n",
        "  * Which feature should the startup focus on?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73e9346-3220-4860-b609-22540ad7fb6e",
      "metadata": {
        "id": "c73e9346-3220-4860-b609-22540ad7fb6e"
      },
      "source": [
        "### The dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f561d828-da7d-49a6-a990-be0ab899e90f",
      "metadata": {
        "id": "f561d828-da7d-49a6-a990-be0ab899e90f"
      },
      "source": [
        "Using phone call data from a European bank, this project will be building models that predict if a customer will subscribe to a term deposit, a type of financial product. This project is a partnership with a startup focused on providing ML solutions for European banks.\n",
        "\n",
        "The dataset consists of the following columns:\n",
        "* `age`\n",
        "  * Numeric\n",
        "  * The age of the customer\n",
        "* `job`\n",
        "  * Categorical\n",
        "  * The job category of the customer\n",
        "* `marital`\n",
        "  * Categorical\n",
        "  * Whether the customer is married\n",
        "* `education`\n",
        "  * Categorical\n",
        "  * The customer's level of education\n",
        "* `default`\n",
        "  * Binary\n",
        "  * If the customer has credit in default or not\n",
        "* `balance`\n",
        "  * Numeric\n",
        "  * Average yearly balance in Euros\n",
        "* `housing`\n",
        "  * Binary\n",
        "  * If the customer has a housing loan or not\n",
        "* `loan`\n",
        "  * Binary\n",
        "  * If the customer has a personal loan\n",
        "* `contact`\n",
        "  * Categorical\n",
        "  * The type of contact communication\n",
        "* `day`\n",
        "  * Numeric\n",
        "  * Last contact day of the month\n",
        "* `month`\n",
        "  * Categorical\n",
        "  * Last contact month of the year\n",
        "* `duration`\n",
        "  * Numeric\n",
        "  * Duration of the last phone call with the customer\n",
        "* `campaign`\n",
        "  * Numeric\n",
        "  * The number of contacts performed during this campaign and for this client, which includes the last contact"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "866a70ee-45dd-402c-b132-593a220dabec",
      "metadata": {
        "id": "866a70ee-45dd-402c-b132-593a220dabec"
      },
      "source": [
        "The final column, `y`, is the target of the dataset and shows whether the client subscribed to a term deposit."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f15887c-7c0d-4e8a-a6ac-8b1245917fe1",
      "metadata": {
        "id": "4f15887c-7c0d-4e8a-a6ac-8b1245917fe1"
      },
      "source": [
        "## Table of Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98d80d5-bba0-4c15-872b-a71026f545a4",
      "metadata": {
        "id": "d98d80d5-bba0-4c15-872b-a71026f545a4"
      },
      "source": [
        "1. [EDA](#eda)\n",
        " * [Non-visual data analysis](#neda) of the data: check `dtype`, look at broad trends in data\n",
        " * [Visualization](#viz) of the data\n",
        "   * [Figure 1: Barplots of **categorical** features](#fig1)\n",
        "   * [Figure 2: Histograms of **continuous** features](#fig2)\n",
        "   * [Figure 3: Boxplots of **continuous** features](#fig3)\n",
        "   * [Figure 4: Correlation matrix of **continuous** features](#fig4)\n",
        "   * [Figure 5: Correlation matrix of **categorical** features](#fig5)\n",
        "   * What about [scatterplots?](#scat)\n",
        "2. [Modeling](#mod)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec43663-7e38-44ee-80d5-df9885aa7c12",
      "metadata": {
        "id": "cec43663-7e38-44ee-80d5-df9885aa7c12"
      },
      "source": [
        "## Imports and Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7a73c419-37ae-4e69-9b29-fbaf125cbf09",
      "metadata": {
        "id": "7a73c419-37ae-4e69-9b29-fbaf125cbf09"
      },
      "outputs": [],
      "source": [
        "# ignore warnings for seaborn\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", module=\"seaborn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "SzLMEB-iRSwn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzLMEB-iRSwn",
        "outputId": "bce48acb-9783-43ef-dc71-ca93b8d74ec3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.66.4)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.26.4)\n",
            "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.4)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.4)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.0.1)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.12.3)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.6.3)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.4.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.2.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.2.1)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.4.1)\n",
            "Requirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.7.1)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.15.0)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.2.1)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.10.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.14.2)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret) (24.1)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.4.0->pycaret) (0.5.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.19.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.8)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->pycaret) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.14.0->pycaret) (9.0.0)\n",
            "Requirement already satisfied: dash>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (2.17.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.6)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.3)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.10)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (2024.7.4)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.12.2)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.19.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category-encoders>=2.4.0->pycaret) (1.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.5)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.1.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycaret\n",
        "# !pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2b2c9e0e-6abf-460b-81e3-4e2faa22b8ac",
      "metadata": {
        "id": "2b2c9e0e-6abf-460b-81e3-4e2faa22b8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "c1c94d7b-40de-48ca-b99b-f9765fe4352e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'RadiusNeighborsClassMode' from 'sklearn.metrics._pairwise_distances_reduction' (/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4338d994f76c>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# from sklearn.compose import ColumnTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# from sklearn.pipeline import Pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0manomaly\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bagging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaggingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEnsemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m from ._forest import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegressorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_to_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHasMethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRealNotInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from ._classes import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mBaseDecisionTree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_splitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_criterion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/tree/_criterion.pyx\u001b[0m in \u001b[0;36minit sklearn.tree._criterion\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/tree/_splitter.pyx\u001b[0m in \u001b[0;36minit sklearn.tree._splitter\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36minit sklearn.tree._tree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ball_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVALID_METRICS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVALID_METRICS_SPARSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_graph_by_row_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRadiusNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from ._graph import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mKNeighborsTransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from ..metrics._pairwise_distances_reduction import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mArgKminClassMode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mRadiusNeighborsClassMode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'RadiusNeighborsClassMode' from 'sklearn.metrics._pairwise_distances_reduction' (/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from pycaret.classification import setup,compare_models,create_model,plot_model,evaluate_model\n",
        "# from pycaret.regression import *\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3347e3a1-ee42-4530-8691-e81b491b69f1",
      "metadata": {
        "id": "3347e3a1-ee42-4530-8691-e81b491b69f1"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# from datetime import datetime\n",
        "# from pathlib import Path\n",
        "# import inspect\n",
        "\n",
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "# from sklearn.metrics import roc_curve,auc,roc_auc_score\n",
        "\n",
        "# from xgboost import XGBClassifier\n",
        "# from sklearn.ensemble import ExtraTreesClassifier\n",
        "# from sklearn.feature_selection import RFE\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# import lightgbm as lgb\n",
        "# from lightgbm import LGBMClassifier\n",
        "# from lightgbm import plot_importance\n",
        "\n",
        "# from sklearn.ensemble import StackingClassifier\n",
        "# from sklearn.ensemble import VotingClassifier\n",
        "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "# from numpy import mean\n",
        "# from numpy import std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9e5c419-09a9-4f1b-b79b-5b29f5283a4e",
      "metadata": {
        "id": "f9e5c419-09a9-4f1b-b79b-5b29f5283a4e"
      },
      "outputs": [],
      "source": [
        "# simple function to generate random integers\n",
        "\n",
        "def rand_gen(low=1,high=1e4):\n",
        "    '''\n",
        "    Generates a pseudo-random integer\n",
        "    consisting of up to four digits\n",
        "    '''\n",
        "    rng=np.random.default_rng()\n",
        "    random_state=int(rng.integers(low=low,high=high))\n",
        "    return random_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df08b11b-44df-4634-8511-a25455ec4275",
      "metadata": {
        "id": "df08b11b-44df-4634-8511-a25455ec4275"
      },
      "outputs": [],
      "source": [
        "def get_variable_name(var):\n",
        "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
        "    return [name for name, val in callers_local_vars if val is var]\n",
        "\n",
        "def fileDaterSaver(location: str,\n",
        "                   filetype: str,\n",
        "                   object_,\n",
        "                   extra: str = '',\n",
        "                   verbose: bool = True):\n",
        "\n",
        "    '''\n",
        "    Function that gets a timestamped filename and saves it\n",
        "    to a user-specified location.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    location: str - The location where the file will be saved.\n",
        "    filetype: str - The type of the file to save ('csv' or 'json').\n",
        "    object_: The object to be saved. Should be a pandas DataFrame\n",
        "        for 'csv' or serializable for 'json'.\n",
        "    extra: str - Additional string to include in the filename.\n",
        "    verbose: bool - Whether to print verbose messages.\n",
        "    '''\n",
        "\n",
        "    # get current date and time\n",
        "    current_datetime = datetime.now()\n",
        "\n",
        "    # print current date and time to check\n",
        "    if verbose:\n",
        "        print('current_datetime:', current_datetime)\n",
        "\n",
        "    # format the datetime for a filename\n",
        "    datetime_suffix = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "    # create filename with the datetime suffix\n",
        "    if extra != '':\n",
        "        file_name = f'{location}{extra}_{datetime_suffix}.{filetype}'\n",
        "    else:\n",
        "        file_name = f'{location}{datetime_suffix}.{filetype}'\n",
        "\n",
        "    # print file name\n",
        "    if verbose:\n",
        "        print(file_name)\n",
        "\n",
        "    # save object\n",
        "    if filetype == 'csv':\n",
        "        object_.to_csv(file_name, index=True)\n",
        "    elif filetype == 'json':\n",
        "        with open(file_name, 'w') as file:\n",
        "            file.write(json.dumps(object_, default=str))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Use 'csv' or 'json'.\")\n",
        "\n",
        "    # confirm save\n",
        "    file_path = Path(file_name)\n",
        "    if file_path.exists():\n",
        "        variable_name = get_variable_name(object_)\n",
        "        if variable_name:\n",
        "            print(f'Successfully saved {variable_name[0]} to {file_path}')\n",
        "        else:\n",
        "            print(f'Successfully saved object to {file_path}')\n",
        "    else:\n",
        "        print(\"File save error.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed=rand_gen()\n",
        "seed"
      ],
      "metadata": {
        "id": "QJuJyOSRMAio"
      },
      "id": "QJuJyOSRMAio",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size=0.2\n",
        "test_size"
      ],
      "metadata": {
        "id": "w1DRWNJkMCZw"
      },
      "id": "w1DRWNJkMCZw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "76590fed-93ce-44de-bc02-ad395a92a8ad",
      "metadata": {
        "id": "76590fed-93ce-44de-bc02-ad395a92a8ad"
      },
      "source": [
        "## EDA <a name='eda'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f41ed000-fd7a-4eea-beb2-47dfd641e158",
      "metadata": {
        "id": "f41ed000-fd7a-4eea-beb2-47dfd641e158"
      },
      "source": [
        "### Non-visual data analysis <a name='neda'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fLmFQtkSBxS",
      "metadata": {
        "id": "2fLmFQtkSBxS"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df=pd.read_csv('/content/drive/MyDrive/2_data.csv')\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "ubeWT8CMcsgV"
      },
      "id": "ubeWT8CMcsgV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url=''\n",
        "# df=pd.read_csv(url)\n",
        "# df.head(3)"
      ],
      "metadata": {
        "id": "-eEx0DSkIeBH"
      },
      "id": "-eEx0DSkIeBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44e2a9a-5663-41f3-a4a6-3a5da75e8a70",
      "metadata": {
        "id": "a44e2a9a-5663-41f3-a4a6-3a5da75e8a70"
      },
      "outputs": [],
      "source": [
        "# if not in Google Colab:\n",
        "\n",
        "# read in data\n",
        "# df=pd.read_csv('../data/2_data.csv')\n",
        "# df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U -q PyDrive2\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "fkMqzVSuJB-u"
      },
      "id": "fkMqzVSuJB-u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link='https://drive.google.com/file/d/1uIUzYWMQA_hl1odTnBTfwCV4m8K8BqMt/view?usp=share_link'\n",
        "df=pd.read_csv(link)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "jqy_J5D4JDmh"
      },
      "id": "jqy_J5D4JDmh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d504d8-387b-48ad-b38c-cd9643008132",
      "metadata": {
        "id": "19d504d8-387b-48ad-b38c-cd9643008132"
      },
      "outputs": [],
      "source": [
        "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a83dedcb-3dc4-42f4-82b7-6d2daccc6e16",
      "metadata": {
        "id": "a83dedcb-3dc4-42f4-82b7-6d2daccc6e16"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1564bfb5-45dd-4033-b764-8f501f328b08",
      "metadata": {
        "id": "1564bfb5-45dd-4033-b764-8f501f328b08"
      },
      "source": [
        "There are no nulls in the dataset, which makes our lives easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9356447-d016-4849-9e8c-3de5ad279bec",
      "metadata": {
        "id": "a9356447-d016-4849-9e8c-3de5ad279bec"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597a3834-46d1-4b26-8066-ab68d3117545",
      "metadata": {
        "id": "597a3834-46d1-4b26-8066-ab68d3117545"
      },
      "source": [
        "We can glean the following insights from this table:\n",
        "* The mean values for the `age`, `day`, and `campaign` columns are about equal to the 50th percentile\n",
        "  * The distribution of the data may be symmetric\n",
        "* The max value in each column besides `age` and `day` is much larger than the column's 75th percentile\n",
        "  * This suggests there could be outliers\n",
        "  * `age` and `day` are more or less categorical, so it makes sense that the max age is 95 and max day is 31"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3b3d672-3180-4ce0-9cf9-c07e30bfd2b3",
      "metadata": {
        "id": "e3b3d672-3180-4ce0-9cf9-c07e30bfd2b3"
      },
      "source": [
        "What if we compare the subset of the data that had a positive `y` outcome to those that had a negative outcome?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0fadeaa-2aa6-4033-a3dc-9d0269561a6b",
      "metadata": {
        "id": "b0fadeaa-2aa6-4033-a3dc-9d0269561a6b"
      },
      "outputs": [],
      "source": [
        "# customers in the dataset who did get a loan\n",
        "df_yes = df[df['y'] == 'yes']\n",
        "df_yes.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f73fe0-ffaa-4e07-beb1-c3080457c670",
      "metadata": {
        "id": "c7f73fe0-ffaa-4e07-beb1-c3080457c670"
      },
      "outputs": [],
      "source": [
        "# customers in the dataset who did not get a loan\n",
        "df_no = df[df['y'] == 'no']\n",
        "df_no.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7587127e-3db7-4a67-a65c-63237f4af0df",
      "metadata": {
        "id": "7587127e-3db7-4a67-a65c-63237f4af0df",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(f\"{df_yes.shape[0]/df.shape[0]*100}% of the dataset has positive outcomes, while {round(df_no.shape[0]/df.shape[0]*100,2)}% of the dataset has negative outcomes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f974863f-76db-4773-9839-d9c484e5e894",
      "metadata": {
        "id": "f974863f-76db-4773-9839-d9c484e5e894"
      },
      "source": [
        "We can see:\n",
        "* There is a large class imbalance in the dataset\n",
        "* The mean values are roughly the same across the numerical columns and loan outcomes\n",
        "  * Except for duration, which is about 3x as less for calls that don't end with a sale (`y`=no)\n",
        "* The max values for `balance` and `campaign` are about 2.25x and 2x as large for `y`=no"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a7a575-229e-41b7-970a-56ba745dbc97",
      "metadata": {
        "id": "b3a7a575-229e-41b7-970a-56ba745dbc97"
      },
      "source": [
        "Let's do some more aggregations to tease apart the differences between the different classes within each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236a7fcd-0329-415b-9450-123a23bfa83b",
      "metadata": {
        "id": "236a7fcd-0329-415b-9450-123a23bfa83b"
      },
      "outputs": [],
      "source": [
        "# functions to compute the quantiles\n",
        "\n",
        "def q25(x):\n",
        "    return x.quantile(0.25)\n",
        "\n",
        "def q50(x):\n",
        "    return x.quantile(0.50)\n",
        "\n",
        "def q75(x):\n",
        "    return x.quantile(0.75)\n",
        "\n",
        "def iqr(x):\n",
        "    return q75(x)-q25(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe019bd7-5270-4831-b5a4-c504bfbc602e",
      "metadata": {
        "id": "fe019bd7-5270-4831-b5a4-c504bfbc602e"
      },
      "source": [
        "We can edit this code to slice and dice the dataset as we please:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9287ad-91c4-4697-b903-1bb96c89a0f5",
      "metadata": {
        "id": "bf9287ad-91c4-4697-b903-1bb96c89a0f5"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00aa490-c632-431a-96ae-ecf4b02aa847",
      "metadata": {
        "id": "b00aa490-c632-431a-96ae-ecf4b02aa847"
      },
      "outputs": [],
      "source": [
        "groupby_list=['count','mean','std','min',q25,q50,q75,iqr]\n",
        "df.groupby([\n",
        "    # 'age',\n",
        "    'job',\n",
        "    # 'marital',\n",
        "    # 'education',\n",
        "    # 'default',\n",
        "    # 'housing',\n",
        "    # 'loan',\n",
        "    # 'contact',\n",
        "    # 'day',\n",
        "    # 'month',\n",
        "    # 'y'\n",
        "]).agg(\n",
        "    {\n",
        "        'balance':groupby_list,\n",
        "        # 'duration':groupby_list,\n",
        "        # 'campaign':groupby_list\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2757428b-b424-4040-8821-d7402a5af943",
      "metadata": {
        "id": "2757428b-b424-4040-8821-d7402a5af943"
      },
      "source": [
        "There are different mean balances depending on what job the customer is in, which is to be expected: a blue-collar worker is not typically making the same amount of money that someone in management makes, so the balance in their bank account would be different too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad59952-9dcc-47c9-9f1f-d6ec727b0eea",
      "metadata": {
        "id": "2ad59952-9dcc-47c9-9f1f-d6ec727b0eea"
      },
      "outputs": [],
      "source": [
        "# create dictionary of unique values\n",
        "dict_unique={col:df[col].nunique() for col in df.columns}\n",
        "\n",
        "# this is a little unwieldy\n",
        "# but it will give us a sense of\n",
        "# HOW MANY unique values there are\n",
        "dict_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4acad808-277a-467f-a454-270c8b24b3ae",
      "metadata": {
        "id": "4acad808-277a-467f-a454-270c8b24b3ae"
      },
      "source": [
        "We can tell which columns are categorical. For example, there are...\n",
        "* 12 kinds of jobs\n",
        "* 4 education levels  \n",
        "\n",
        "...in the datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d086f5f9-4c66-47cc-b330-dde788394461",
      "metadata": {
        "id": "d086f5f9-4c66-47cc-b330-dde788394461"
      },
      "outputs": [],
      "source": [
        "# create dictionary of unique values\n",
        "dict_nunique={col:df[col].unique() for col in df.columns}\n",
        "\n",
        "# this is a little unwieldy\n",
        "# but it will give us a sense of\n",
        "# WHAT the unique values are\n",
        "dict_nunique"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07c5c4f4-97ea-4763-a7d0-c196783eef0b",
      "metadata": {
        "id": "07c5c4f4-97ea-4763-a7d0-c196783eef0b"
      },
      "source": [
        "Nothing too surprising jumps out at us here, so we'll need to use more... _visual_ methods to understand the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9473f62-b437-4ccd-a13a-6dc1c53cb606",
      "metadata": {
        "id": "d9473f62-b437-4ccd-a13a-6dc1c53cb606"
      },
      "source": [
        "### Visualization <a name='viz'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caba9795-a9e2-4175-9e2b-d68a0894a122",
      "metadata": {
        "id": "caba9795-a9e2-4175-9e2b-d68a0894a122"
      },
      "source": [
        "#### Figure 1: Barplots of Categorical features <a name='fig1'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "340d8baf-a728-480e-bed8-8a3656431494",
      "metadata": {
        "id": "340d8baf-a728-480e-bed8-8a3656431494"
      },
      "source": [
        "Make a big figure with all the categorical features:\n",
        "* `job`\n",
        "* `marital`\n",
        "* `education`\n",
        "* `default`\n",
        "* `housing`\n",
        "* `loan`\n",
        "* `contact`\n",
        "* `day`\n",
        "* `month`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212c5bfa-e074-4b6e-8e70-a6394312b360",
      "metadata": {
        "id": "212c5bfa-e074-4b6e-8e70-a6394312b360"
      },
      "outputs": [],
      "source": [
        "# make dictionary of just the categorical variables\n",
        "cat_nunique=copy.deepcopy(dict_nunique)\n",
        "del cat_nunique['age']\n",
        "del cat_nunique['balance']\n",
        "del cat_nunique['duration']\n",
        "del cat_nunique['campaign']\n",
        "del cat_nunique['y']\n",
        "cat_nunique={key: sorted(value) for key, value in cat_nunique.items()}\n",
        "print(cat_nunique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e271b05-f4de-41e8-9b3d-37a87486284b",
      "metadata": {
        "id": "5e271b05-f4de-41e8-9b3d-37a87486284b"
      },
      "outputs": [],
      "source": [
        "job_order=list(df['job'].unique())\n",
        "job_order.sort()\n",
        "job_order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e0d0a6-b04e-4486-bdd5-ae41d473b547",
      "metadata": {
        "id": "b7e0d0a6-b04e-4486-bdd5-ae41d473b547"
      },
      "outputs": [],
      "source": [
        "cat_nunique['month']=['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07670898-d8cd-4732-86b8-82edb3936355",
      "metadata": {
        "id": "07670898-d8cd-4732-86b8-82edb3936355",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# get total number of plots\n",
        "num_plots=len(cat_nunique)*2\n",
        "\n",
        "# create subplots\n",
        "fig,axes=plt.subplots(num_plots,1,figsize=(15,num_plots*4))\n",
        "plt.suptitle(t='Counts of Categorical Variables in Dataset',y=.999)\n",
        "plt.tight_layout()\n",
        "\n",
        "# flatten axes for easy indexing\n",
        "axes=axes.flatten()\n",
        "\n",
        "# plot each column\n",
        "for i, (col, order) in enumerate(cat_nunique.items()):\n",
        "#     plot 'no' part\n",
        "    ax1=sns.countplot(data=df_no,x=col,palette='colorblind', dodge=True, order=order,ax=axes[i*2])\n",
        "    # ax1.set_title(f'{col.capitalize()} Distribution for Failed Campaigns')\n",
        "    for p in ax1.patches:\n",
        "        ax1.annotate(format(p.get_height(), '.0f'),\n",
        "                     (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                     ha = 'center', va = 'center',\n",
        "                     xytext = (0, 4),\n",
        "                     textcoords = 'offset points')\n",
        "    ax1.text(ax1.get_xlim()[1]+(ax1.get_xlim()[1])*(-0.17),\n",
        "             ax1.get_ylim()[1] - (ax1.get_ylim()[1])*(1/5),\n",
        "             f'Variable: {col.capitalize()}\\nFailed Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "    # Plot 'yes' part\n",
        "    ax2 = sns.countplot(data=df_yes,x=col,palette='colorblind',dodge=True,order=order,ax=axes[i*2 + 1])\n",
        "    # ax2.set_title(f'{col.capitalize()} Distribution for Successful Campaigns')\n",
        "    for p in ax2.patches:\n",
        "        ax2.annotate(format(p.get_height(), '.0f'),\n",
        "                     (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                     ha = 'center', va = 'center',\n",
        "                     xytext = (0, 4),\n",
        "                     textcoords = 'offset points')\n",
        "    ax2.text(ax2.get_xlim()[1]+(ax2.get_xlim()[1])*(-0.17),\n",
        "             ax2.get_ylim()[1] - (ax2.get_ylim()[1])*(1/5),\n",
        "             f'Variable: {col.capitalize()}\\nSuccessful Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "plt.savefig('../figs/2_countcategorical.pdf')\n",
        "plt.savefig('../figs/2_countcategorical.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea37d543-09ab-4d80-bf8d-7f8355dcb426",
      "metadata": {
        "id": "ea37d543-09ab-4d80-bf8d-7f8355dcb426"
      },
      "source": [
        "There is a lot to observe here, but note that although the values differ drastically between successful and failed campaigns, the patterns are similar for most of the features.\n",
        "\n",
        "Also notable is that there were no calls made to customers in the month of September."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4dbb88a-6960-4990-8a2c-f61c47cd1d85",
      "metadata": {
        "id": "f4dbb88a-6960-4990-8a2c-f61c47cd1d85",
        "tags": []
      },
      "source": [
        "#### Figure 2: Histograms of Continuous Features <a name='fig2'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a1f847-89ac-4745-9879-389fe066976f",
      "metadata": {
        "id": "e5a1f847-89ac-4745-9879-389fe066976f"
      },
      "outputs": [],
      "source": [
        "# make dictionary of just the categorical variables\n",
        "num_nunique=copy.deepcopy(dict_nunique)\n",
        "del num_nunique['job']\n",
        "del num_nunique['marital']\n",
        "del num_nunique['education']\n",
        "del num_nunique['default']\n",
        "del num_nunique['housing']\n",
        "del num_nunique['loan']\n",
        "del num_nunique['contact']\n",
        "del num_nunique['day']\n",
        "del num_nunique['month']\n",
        "del num_nunique['y']\n",
        "num_nunique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d0eb7e-185b-4761-b6b8-c3c37d2d6451",
      "metadata": {
        "id": "d9d0eb7e-185b-4761-b6b8-c3c37d2d6451"
      },
      "outputs": [],
      "source": [
        "# get total number of plots\n",
        "num_plots=len(num_nunique)*2\n",
        "\n",
        "# create subplots\n",
        "fig,axes=plt.subplots(num_plots,1,figsize=(15,num_plots*4))\n",
        "plt.suptitle(t='Histograms of Continuous Variables in Dataset',y=.999)\n",
        "plt.tight_layout()\n",
        "\n",
        "# flatten axes for easy indexing\n",
        "axes=axes.flatten()\n",
        "\n",
        "# plot each column\n",
        "for i, (col, order) in enumerate(num_nunique.items()):\n",
        "#     plot 'no' part\n",
        "    ax1=sns.histplot(data=df_no,x=col,color='cornflowerblue',ax=axes[i*2])\n",
        "    ax1.text(ax1.get_xlim()[1]+(ax1.get_xlim()[1])*(-0.17),\n",
        "             ax1.get_ylim()[1] - (ax1.get_ylim()[1])*(1/5),\n",
        "             f'Variable: {col.capitalize()}\\nFailed Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "    # Plot 'yes' part\n",
        "    ax2 = sns.histplot(data=df_yes,x=col,color='orange',ax=axes[i*2 + 1])\n",
        "    ax2.text(ax2.get_xlim()[1]+(ax2.get_xlim()[1])*(-0.17),\n",
        "             ax2.get_ylim()[1] - (ax2.get_ylim()[1])*(1/5),\n",
        "             f'Variable: {col.capitalize()}\\nSuccessful Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "plt.savefig('../figs/2_histograms.pdf')\n",
        "plt.savefig('../figs/2_histograms.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbd7643e-ce07-403d-a077-1966119ffebd",
      "metadata": {
        "id": "dbd7643e-ce07-403d-a077-1966119ffebd"
      },
      "source": [
        "The patterns between successful and failed campaigns' continuous data are mostly similar, although the X and Y axes are different. The one feature that I see is different is the distribution for duration for successful campaigns is wider than those for failed campaigns. Boxplots may clear this up for us."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd34308-3f68-4981-be99-a8b7fd88cbaf",
      "metadata": {
        "id": "6bd34308-3f68-4981-be99-a8b7fd88cbaf"
      },
      "source": [
        "#### Figure 3: Boxplots of Continuous Features <a name='fig3'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ZFtzdk3cEni",
      "metadata": {
        "id": "8ZFtzdk3cEni"
      },
      "outputs": [],
      "source": [
        "order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67605bbd-9f65-4074-95be-3d9ab480980f",
      "metadata": {
        "id": "67605bbd-9f65-4074-95be-3d9ab480980f"
      },
      "outputs": [],
      "source": [
        "# get total number of plots\n",
        "num_plots=len(num_nunique)*2\n",
        "\n",
        "# create subplots\n",
        "fig,axes=plt.subplots(num_plots,1,figsize=(15,num_plots*4))\n",
        "plt.suptitle(t='Histograms of Continuous Variables in Dataset',y=.999)\n",
        "plt.tight_layout()\n",
        "\n",
        "# flatten axes for easy indexing\n",
        "axes=axes.flatten()\n",
        "\n",
        "# plot each column\n",
        "for i, (col, order) in enumerate(num_nunique.items()):\n",
        "#     plot 'no' part\n",
        "    ax1=sns.boxplot(data=df_no,x=col,color='cornflowerblue',ax=axes[i*2])\n",
        "    ax1.text(ax1.get_xlim()[1]+(ax1.get_xlim()[1])*(-0.17),\n",
        "             ax1.get_ylim()[1] - (ax1.get_ylim()[1])*(1/5),\n",
        "             f'Variable: {col.capitalize()}\\nFailed Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "    # Plot 'yes' part\n",
        "    ax2 = sns.boxplot(data=df_yes,x=col,color='orange',ax=axes[i*2 + 1])\n",
        "    ax2.text(ax2.get_xlim()[1]+(ax2.get_xlim()[1])*(-0.17),\n",
        "             ax2.get_ylim()[1] - (ax2.get_ylim()[1])*(1/5),\n",
        "             f'Variable: {col.capitalize()}\\nSuccessful Campaigns', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "plt.savefig('../figs/2_boxplots.pdf')\n",
        "plt.savefig('../figs/2_boxplots.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a04bc5-2031-4ea0-bb28-7755e4bb3bd5",
      "metadata": {
        "id": "b3a04bc5-2031-4ea0-bb28-7755e4bb3bd5"
      },
      "source": [
        "Duration does indeed seem different, though recall that this feature is describing how long the last phone call was with the customer. It may not tell us that much."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1cd63d0-5316-4191-8db6-56bdc3287b92",
      "metadata": {
        "id": "b1cd63d0-5316-4191-8db6-56bdc3287b92"
      },
      "source": [
        "#### Figure 4: Correlation Matrix of Continuous Features <a name='fig4'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97L7Q0-CeTsx",
      "metadata": {
        "id": "97L7Q0-CeTsx"
      },
      "outputs": [],
      "source": [
        "df_num=df[['age','balance','duration','campaign']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d4a708-bff3-41b2-b23d-ef5e6c4f1915",
      "metadata": {
        "id": "f0d4a708-bff3-41b2-b23d-ef5e6c4f1915"
      },
      "outputs": [],
      "source": [
        "# compute correlation matrix\n",
        "corr=df_num[['age','balance','duration','campaign']].corr()\n",
        "\n",
        "# generate mask for the upper triangle\n",
        "mask=np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# set up matplotlib figure\n",
        "f,ax = plt.subplots(figsize=(5, 4))\n",
        "\n",
        "# draw heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr,mask=mask,cmap='coolwarm',#vmax=1,vmin=-1,\n",
        "            center=0,\n",
        "            square=True,linewidths=.5,annot=True,\n",
        "            fmt='.2f',cbar_kws={\"shrink\":.5})\n",
        "plt.title('Correlation Matrix of Numerical Features\\n$Higher$ $absolute$ $value$ $indicates$ $stronger$ $correlation$')\n",
        "plt.tight_layout()\n",
        "\n",
        "# save fig\n",
        "plt.savefig('../figs/2_corrmatrix_num.pdf')\n",
        "plt.savefig('../figs/2_corrmatrix_num.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8b1ee8-e1cb-4988-b177-a2d28e110835",
      "metadata": {
        "id": "7e8b1ee8-e1cb-4988-b177-a2d28e110835"
      },
      "source": [
        "It's good to see that there are no strong correlations with the numerical data. `age`:`balance` makes sense because as you age, you will have had a longer time to accrue more money.\n",
        "\n",
        "Let's now look at the categorical data now:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f923b60d-bf3a-499e-aca9-f8be92dd445f",
      "metadata": {
        "id": "f923b60d-bf3a-499e-aca9-f8be92dd445f"
      },
      "source": [
        "#### Figure 5: Correlation Matrix of Categorical Features <a name='fig5'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072151f8-7ceb-438e-90c0-91dbc531e3f0",
      "metadata": {
        "id": "072151f8-7ceb-438e-90c0-91dbc531e3f0"
      },
      "outputs": [],
      "source": [
        "# make a df of just the categorical values\n",
        "df_cat=df[['job','marital','education','default','housing','loan','contact','day','month','y']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9383c3-0de4-4d65-b072-60dcc38b5c77",
      "metadata": {
        "id": "4e9383c3-0de4-4d65-b072-60dcc38b5c77"
      },
      "outputs": [],
      "source": [
        "def cramers_v(x, y):\n",
        "    \"\"\"Calculate CramÃ©r's V statistic for categorical-categorical association.\"\"\"\n",
        "    confusion_matrix = pd.crosstab(x, y)\n",
        "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
        "    n = confusion_matrix.sum().sum()\n",
        "    phi2 = chi2 / n\n",
        "    r, k = confusion_matrix.shape\n",
        "    phi2corr = max(0, phi2 - ((k-1)*(r-1)) / (n-1))\n",
        "    rcorr = r - ((r-1)**2) / (n-1)\n",
        "    kcorr = k - ((k-1)**2) / (n-1)\n",
        "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
        "\n",
        "def cramers_v_matrix(df):\n",
        "    \"\"\"Compute a matrix of CramÃ©r's V statistics for all pairs of categorical columns in a DataFrame.\"\"\"\n",
        "    cols = df.columns\n",
        "    n = len(cols)\n",
        "    cv_matrix = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            cv_matrix[i, j] = cramers_v(df[cols[i]], df[cols[j]])\n",
        "    return pd.DataFrame(cv_matrix, index=cols, columns=cols)\n",
        "\n",
        "# Compute CramÃ©r's V matrix\n",
        "cv_matrix = cramers_v_matrix(df_cat)\n",
        "\n",
        "# generate mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(cv_matrix, dtype=bool))\n",
        "\n",
        "# Plot the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cv_matrix, annot=True, cmap='coolwarm', #vmin=-1, vmax=1,\n",
        "            mask=mask, cbar_kws={\"shrink\": .8},fmt='.2f')\n",
        "\n",
        "plt.title(\"CramÃ©r's V Correlation Matrix\")\n",
        "\n",
        "# save fig\n",
        "plt.savefig('../figs/2_corrmatrix_categorical.pdf')\n",
        "plt.savefig('../figs/2_corrmatrix_categorical.png')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "090a3916-3a58-47f1-93f9-a6a49d0589c3",
      "metadata": {
        "id": "090a3916-3a58-47f1-93f9-a6a49d0589c3"
      },
      "source": [
        "This is a great figure. Most correlations are very slight, but there are a few stronger correlations, like `contact`:`month`, `housing`:`month`, `job`:`education`, and `day`:`month`. These correlations mostly make sense."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2af0ec-16d5-4dc6-a7c0-928a617684e1",
      "metadata": {
        "id": "ff2af0ec-16d5-4dc6-a7c0-928a617684e1"
      },
      "source": [
        "#### What about Scatterplots? <a name='scat'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16a4cfff-4714-49de-99cb-6c0ac9b893fa",
      "metadata": {
        "id": "16a4cfff-4714-49de-99cb-6c0ac9b893fa"
      },
      "source": [
        "Scatterplots do not seem to give us much insight. The data points are very dispersed and a pattern does not readily emerge:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f20060ed-668c-4988-8ca7-073425715e8a",
      "metadata": {
        "id": "f20060ed-668c-4988-8ca7-073425715e8a"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data=df,hue='y')\n",
        "\n",
        "plt.savefig('../figs/2_pairplot.pdf')\n",
        "plt.savefig('../figs/2_pairplot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7c178b-eed7-44e0-a5e4-6d3e5b23b46e",
      "metadata": {
        "id": "0d7c178b-eed7-44e0-a5e4-6d3e5b23b46e"
      },
      "outputs": [],
      "source": [
        "# reinstate warning labels\n",
        "import warnings\n",
        "warnings.filterwarnings(\"default\", module=\"seaborn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1ad854-c659-4b08-81cb-323863e3497d",
      "metadata": {
        "id": "af1ad854-c659-4b08-81cb-323863e3497d"
      },
      "source": [
        "## Modeling <a name='mod'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c62bb50a-ec4b-4158-afe0-8ceacd187620",
      "metadata": {
        "id": "c62bb50a-ec4b-4158-afe0-8ceacd187620"
      },
      "source": [
        "### Goals recap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed783d3-f06d-4ffb-b0cc-28048bb44f6a",
      "metadata": {
        "id": "eed783d3-f06d-4ffb-b0cc-28048bb44f6a"
      },
      "source": [
        "To achieve this project's goals, we have to run models. As a reminder, this project is aiming to predict customer behavior. Specifically, we are training models to determine if a customer will buy a term deposit loan.\n",
        "\n",
        "We are aiming to achieve â‰¥81% accuracy with the modeling\n",
        "  * Use a 5-fold cross validation strategy and take the average performance score.\n",
        "\n",
        "Bonus goals include:\n",
        "* Determine which customers are most likely to buy the term deposit loan\n",
        "  * Which segments of customers should the client prioritize?\n",
        "* Determine what makes the customer buy the loan\n",
        "  * Which feature should the startup focus on?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95c05809-2f22-425d-9618-5c7b7df828d0",
      "metadata": {
        "id": "95c05809-2f22-425d-9618-5c7b7df828d0"
      },
      "source": [
        "### PyCaret"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217f9fdb-8d4c-4d16-9058-0d2978d9cbea",
      "metadata": {
        "id": "217f9fdb-8d4c-4d16-9058-0d2978d9cbea"
      },
      "source": [
        "[PyCaret](#https://pycaret.gitbook.io/docs) is a library that helps make it easy to experiment on the performance of different ML algorithms so that we can maximize our time on optimizing the best algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification using the OOP syntax, building on the example from [pycaret.gitbook.io](#pycaret.gitbook.io):"
      ],
      "metadata": {
        "id": "lJoByLapP3LI"
      },
      "id": "lJoByLapP3LI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of PyCaret show that Gradient Boosting Classifier gave the best accuracy, at almost 94%!"
      ],
      "metadata": {
        "id": "dz0RebMIUOLd"
      },
      "id": "dz0RebMIUOLd"
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = setup(df,\n",
        "             target = 'y',\n",
        "             session_id=seed,\n",
        "             log_experiment=True,\n",
        "             experiment_name='clf1')"
      ],
      "metadata": {
        "id": "84GnaFsqaMC0"
      },
      "id": "84GnaFsqaMC0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save setup results\n",
        "setup_results=pull()\n",
        "# print(setup_results)\n",
        "# setup_results.to_csv('../joblib/2_pycaret_setupresults.csv')\n",
        "from google.colab import files\n",
        "setup_results.to_csv('2_pycaret_setupresults.csv',encoding='utf-8-sig')\n",
        "files.download('2_pycaret_setupresults.csv')"
      ],
      "metadata": {
        "id": "-hBd5OF-MOkw"
      },
      "id": "-hBd5OF-MOkw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model=compare_models(fold=5)\n",
        "\n",
        "# save setup results\n",
        "# best_model.to_csv('../joblib/2_pycaret_bestmodel.csv')\n",
        "best_model=pull()\n",
        "best_model.to_csv('2_pycaret_bestmodel.csv',encoding='utf-8-sig')\n",
        "files.download('2_pycaret_bestmodel.csv')"
      ],
      "metadata": {
        "id": "jSktxcqybEHd"
      },
      "id": "jSktxcqybEHd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbc_model=create_model('gbc')\n",
        "\n",
        "# save gbc_model\n",
        "# gbc_model.pull()\n",
        "# gbc_model.to_csv('../joblib/2_pycaret_gbcmodel.csv')\n",
        "# gbc_model.to_csv('2_pycaret_gbcmodel.csv',encoding='utf-8-sig')\n",
        "# files.download('2_pycaret_gbcmodel.csv')"
      ],
      "metadata": {
        "id": "8dhmsEtaf-8z"
      },
      "id": "8dhmsEtaf-8z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances=plot_model(gbc_model,plot='feature',save=True)\n",
        "feature_importances=plot_model(gbc_model,plot='feature')\n",
        "# save feature_importances\n",
        "# feature_importances.pull()\n",
        "# feature_importances.to_csv('2_pycaret_featureimportances.csv',encoding='utf-8-sig')\n",
        "# files.download('2_pycaret_featureimportances.csv')"
      ],
      "metadata": {
        "id": "jEjqqvOLf9Qu"
      },
      "id": "jEjqqvOLf9Qu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that according to PyCaret, `duration` has the strongest importance on predicting campaign success."
      ],
      "metadata": {
        "id": "_Ims8R34ReXP"
      },
      "id": "_Ims8R34ReXP"
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(gbc_model)"
      ],
      "metadata": {
        "id": "o4ZZtOsxaSdL"
      },
      "id": "o4ZZtOsxaSdL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot AUC\n",
        "plot_model(gbc_model, plot = 'auc')"
      ],
      "metadata": {
        "id": "LaL38jeJQduV"
      },
      "id": "LaL38jeJQduV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AUC-ROC curve is looking pretty healthy: an AUC of over 90% is great. As this is just the base model, let's move to a more rigorous modeling strategy to help us answer this project's questions."
      ],
      "metadata": {
        "id": "cyQNqrKXacmY"
      },
      "id": "cyQNqrKXacmY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the PyCaret experimentation show that the Gradient Boosting Classifier algorithm is best suited for the data. Let's use that for our modeling efforts."
      ],
      "metadata": {
        "id": "JsU0q3o6edcI"
      },
      "id": "JsU0q3o6edcI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Will a customer purchase a loan?"
      ],
      "metadata": {
        "id": "ixBSnhkXenpQ"
      },
      "id": "ixBSnhkXenpQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To answer this question, we need to prepare the dataset so that we have a training and a testing set."
      ],
      "metadata": {
        "id": "yqZSxW3wfiCO"
      },
      "id": "yqZSxW3wfiCO"
    },
    {
      "cell_type": "markdown",
      "id": "c913e2a9-e265-41f9-9b22-60b5543bd439",
      "metadata": {
        "id": "c913e2a9-e265-41f9-9b22-60b5543bd439"
      },
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094a5d71-8e66-4092-8953-ab60cd938908",
      "metadata": {
        "id": "094a5d71-8e66-4092-8953-ab60cd938908"
      },
      "source": [
        "##### Process categorical and continuous columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f28206a-0bc3-48e0-8b6d-e012074144ca",
      "metadata": {
        "id": "9f28206a-0bc3-48e0-8b6d-e012074144ca"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ac08d5-f630-4a8b-b16d-2ccc961cdeaf",
      "metadata": {
        "id": "06ac08d5-f630-4a8b-b16d-2ccc961cdeaf"
      },
      "outputs": [],
      "source": [
        "# make copy to preserve our progress\n",
        "df_modeling=copy.deepcopy(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "308f692b-0db3-46d3-a82c-51c1efb98a3e",
      "metadata": {
        "id": "308f692b-0db3-46d3-a82c-51c1efb98a3e"
      },
      "source": [
        "First, let's convert some categorical columns to binary. This will help me keep track of my progress, as I'll be able to clearly see which columns still need to be processed. Some may need to be discretized, like `job` and `education`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92759d1a-513b-42fd-9ed9-a20a338b0170",
      "metadata": {
        "id": "92759d1a-513b-42fd-9ed9-a20a338b0170"
      },
      "outputs": [],
      "source": [
        "df_modeling['loan'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3bc590-1656-4454-a53c-1a617e1cc301",
      "metadata": {
        "id": "5c3bc590-1656-4454-a53c-1a617e1cc301"
      },
      "outputs": [],
      "source": [
        "df_modeling['y']=df_modeling['y'].map({'yes': 1, 'no': 0})\n",
        "df_modeling['default']=df_modeling['default'].map({'yes': 1, 'no': 0})\n",
        "df_modeling['housing']=df_modeling['housing'].map({'yes': 1, 'no': 0})\n",
        "df_modeling['loan']=df_modeling['loan'].map({'yes': 1, 'no': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c31d5b0-c5c2-402e-a72f-7633f7833ba6",
      "metadata": {
        "id": "6c31d5b0-c5c2-402e-a72f-7633f7833ba6"
      },
      "outputs": [],
      "source": [
        "df_modeling.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235810b4-657a-42ef-ac9c-6d4d8cad011d",
      "metadata": {
        "id": "235810b4-657a-42ef-ac9c-6d4d8cad011d"
      },
      "source": [
        "Those are all the binary features. We still have to get the continuous variables separated and have to discretize, or \"OneHotEncode\" the rest of the categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c61393c-0bf1-407d-a31e-60ef95606c95",
      "metadata": {
        "id": "9c61393c-0bf1-407d-a31e-60ef95606c95"
      },
      "outputs": [],
      "source": [
        "# define the categorical columns\n",
        "cat_cols=['job','marital','education','default','housing','loan','contact','month']\n",
        "df_cat=df_modeling[cat_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35316033-6e65-4a5f-98ca-21a306793995",
      "metadata": {
        "id": "35316033-6e65-4a5f-98ca-21a306793995"
      },
      "outputs": [],
      "source": [
        "df_cat.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a0e290-af10-482d-9a75-ecb73ec4e181",
      "metadata": {
        "id": "01a0e290-af10-482d-9a75-ecb73ec4e181"
      },
      "outputs": [],
      "source": [
        "# make dataframe of continuous variables\n",
        "\n",
        "# set of categorical columns\n",
        "df_cat_set = set(df_cat.columns)\n",
        "# set of all columns\n",
        "df_modeling_set = set(df_modeling.columns)\n",
        "\n",
        "# Find columns that are in df_modeling but not in df_cat\n",
        "difference = df_modeling_set - df_cat_set\n",
        "\n",
        "# Convert the set to list and name it the continuous\n",
        "cont_cols = list(difference)\n",
        "cont_cols.remove('y')\n",
        "\n",
        "# print(\"Columns in DataFrame but not in the list:\\n\",cont_cols)\n",
        "\n",
        "df_cont=df_modeling[cont_cols]\n",
        "df_cont.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3302f05b-04cf-47e3-867d-5425fc80986d",
      "metadata": {
        "id": "3302f05b-04cf-47e3-867d-5425fc80986d"
      },
      "outputs": [],
      "source": [
        "# convert the categorical columns to the 'category' type\n",
        "for col in df_cat.columns:\n",
        "    df_cat.loc[:,col] = df_cat[col].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b95a7b-0e2c-406f-801b-b0105920d931",
      "metadata": {
        "id": "53b95a7b-0e2c-406f-801b-b0105920d931"
      },
      "outputs": [],
      "source": [
        "df_cat.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417f155a-4be8-4a70-abae-b83c39ac9b2c",
      "metadata": {
        "id": "417f155a-4be8-4a70-abae-b83c39ac9b2c"
      },
      "outputs": [],
      "source": [
        "# discretize the categorical columns\n",
        "already_encoded=['default','housing','loan','day']\n",
        "columns_to_encode = [col for col in df_cat.columns if col not in already_encoded]\n",
        "prefixes=columns_to_encode\n",
        "\n",
        "# apply get_dummies\n",
        "df_cat=pd.get_dummies(data=df_cat[columns_to_encode],prefix=prefixes,drop_first=True,dtype='int')\n",
        "\n",
        "# confirm\n",
        "df_cat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9aaa8f-d6b0-4c27-8318-893cff9d93f9",
      "metadata": {
        "id": "5c9aaa8f-d6b0-4c27-8318-893cff9d93f9"
      },
      "outputs": [],
      "source": [
        "# add the continuous and categorical columns together\n",
        "df_x=pd.concat([df_cat,df_cont],axis=1)\n",
        "df_x.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65843804-880d-4caf-b6ca-fcd4cfb6c298",
      "metadata": {
        "id": "65843804-880d-4caf-b6ca-fcd4cfb6c298"
      },
      "source": [
        "##### Define X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e6be7a2-09a3-4bef-a3fa-e77fb4751bc0",
      "metadata": {
        "id": "3e6be7a2-09a3-4bef-a3fa-e77fb4751bc0"
      },
      "outputs": [],
      "source": [
        "X=df_x\n",
        "y=df_modeling[[col for col in df_modeling.columns if col == 'y']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebecde7d-2f95-4cf4-ab5e-8088adbc5045",
      "metadata": {
        "id": "ebecde7d-2f95-4cf4-ab5e-8088adbc5045"
      },
      "source": [
        "##### `train_test_split`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a378f9a0-f7ee-4520-b96d-8b209b207791",
      "metadata": {
        "id": "a378f9a0-f7ee-4520-b96d-8b209b207791"
      },
      "outputs": [],
      "source": [
        "# train/test split\n",
        "X_train, \\\n",
        "X_test, \\\n",
        "y_train, \\\n",
        "y_test = train_test_split(X,\n",
        "                          y,\n",
        "                          test_size=test_size,\n",
        "                          stratify=y,\n",
        "                          random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the dataset ready to go."
      ],
      "metadata": {
        "id": "5rra9G9Nf92y"
      },
      "id": "5rra9G9Nf92y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run model"
      ],
      "metadata": {
        "id": "S-h01JYSgC6O"
      },
      "id": "S-h01JYSgC6O"
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "PCdNmR3ZhIeW"
      },
      "id": "PCdNmR3ZhIeW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll be making a pipeline that includes\n",
        "# a preprocessor to handle features\n",
        "# that need to be scaled\n",
        "\n",
        "# first, separate categorical from continuous features\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "continuous_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "print('features separated')\n",
        "\n",
        "# create pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), continuous_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "print('preprocessor created')"
      ],
      "metadata": {
        "id": "BnDw9Kbraa_J"
      },
      "id": "BnDw9Kbraa_J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(params):\n",
        "    # Create a pipeline with the preprocessor and the classifier\n",
        "    model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', GradientBoostingClassifier(**params))\n",
        "    ])\n",
        "\n",
        "    # Perform cross-validation\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')\n",
        "    # Return the negative mean of the scores as we want to minimize the objective\n",
        "    return {'loss': -scores.mean(), 'status': STATUS_OK}\n",
        "\n",
        "# Define the hyperparameter space\n",
        "space = {\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'n_estimators': hp.choice('n_estimators', range(50, 300)),\n",
        "    'max_depth': hp.choice('max_depth', range(3, 15)),\n",
        "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
        "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 10)),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0)\n",
        "}\n",
        "\n",
        "# Run the optimization\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=100,\n",
        "            trials=trials)"
      ],
      "metadata": {
        "id": "_U6PPzqXjnAQ"
      },
      "id": "_U6PPzqXjnAQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {\n",
        "    'learning_rate': best['learning_rate'],\n",
        "    'n_estimators': range(50, 300)[best['n_estimators']],\n",
        "    'max_depth': range(3, 15)[best['max_depth']],\n",
        "    'min_samples_split': range(2, 10)[best['min_samples_split']],\n",
        "    'min_samples_leaf': range(1, 10)[best['min_samples_leaf']],\n",
        "    'subsample': best['subsample']\n",
        "}\n",
        "\n",
        "# Create a pipeline with the preprocessor and the classifier\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', GradientBoostingClassifier(**best_params))\n",
        "])\n",
        "print('model created')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "print('model trained')\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "id": "ryrOuFZZjqJ2"
      },
      "id": "ryrOuFZZjqJ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6JcOYD-AkF1z"
      },
      "id": "6JcOYD-AkF1z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "apziva",
      "language": "python",
      "name": "apziva"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}